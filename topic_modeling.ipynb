{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Topic Modeling - Latent Dirchlet Allocation (LDA) + time dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"# format code\\n# pip install nb_black\\n%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"# format code\\n# pip install nb_black\\n%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# format code\n",
    "# pip install nb_black\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import pickle\\nimport numpy as np\\nimport pandas as pd\\nimport re\\nimport scipy.sparse\\nimport gensim\\nfrom gensim.corpora import Dictionary\\nfrom gensim import matutils\\nfrom gensim import models\\nfrom gensim.models.coherencemodel import CoherenceModel\\nfrom nltk.corpus import stopwords\\nfrom sklearn.feature_extraction.text import TfidfVectorizer\";\n",
       "                var nbb_formatted_code = \"import pickle\\nimport numpy as np\\nimport pandas as pd\\nimport re\\nimport scipy.sparse\\nimport gensim\\nfrom gensim.corpora import Dictionary\\nfrom gensim import matutils\\nfrom gensim import models\\nfrom gensim.models.coherencemodel import CoherenceModel\\nfrom nltk.corpus import stopwords\\nfrom sklearn.feature_extraction.text import TfidfVectorizer\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import scipy.sparse\n",
    "import gensim\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim import matutils\n",
    "from gensim import models\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### comment condition:  >15words AND 10 unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"stop_words = set(stopwords.words(\\\"german\\\"))\\nstop_words_add = [\\n    \\\"mal\\\",\\n    \\\"mehr\\\",\\n    \\\"ja\\\",\\n    \\\"schon\\\",\\n    \\\"gibt\\\",\\n    \\\"geht\\\",\\n    \\\"hast\\\",\\n    \\\"einfach\\\",\\n    \\\"ganz\\\",\\n    \\\"macht\\\",\\n    \\\"immer\\\",\\n    \\\"tun\\\",\\n    \\\"viele\\\",\\n    \\\"wer\\\",\\n    \\\"sagen\\\",\\n    \\\"w\\u00e4re\\\",\\n    \\\"genau\\\",\\n    \\\"daf\\u00fcr\\\",\\n    \\\"nat\\u00fcrlich\\\",\\n    \\\"seit\\\",\\n    \\\"wurde\\\",\\n    \\\"eigentlich\\\",\\n    \\\"kommt\\\",\\n    \\\"gesagt\\\",\\n    \\\"sagt\\\",\\n    \\\"nie\\\",\\n    \\\"sehen\\\",\\n    \\\"deren\\\",\\n    \\\"versuchen\\\",\\n    \\\"empfehlen\\\",\\n    \\\"m\\u00fcssen\\\",\\n    \\\"kurz\\\",\\n    \\\"wenig\\\",\\n    \\\"erste\\\",\\n    \\\"klare\\\",\\n    \\\"gar\\\",\\n    \\\"grad\\\",\\n    \\\"wohl\\\",\\n    \\\"oft\\\",\\n    \\\"ha\\\",\\n    \\\"schaffen\\\",\\n    \\\"daher\\\",\\n    \\\"schreibt\\\",\\n    \\\"st\\u00e4ndig\\\",\\n    \\\"v\\u00f6llig\\\",\\n    \\\"verdient\\\",\\n    \\\"worden\\\",\\n    \\\"solange\\\",\\n    \\\"k\\u00f6nnt\\\",\\n    \\\"mann\\\",\\n    \\\"zeigt\\\",\\n    \\\"sp\\u00e4ter\\\",\\n    \\\"erste\\\",\\n    \\\"iwelche\\\",\\n    \\\"wen\\\",\\n    \\\"eigenem\\\",\\n    \\\"gr\\u00fcnden\\\",\\n    \\\"ups\\\",\\n    \\\"irgendjemand\\\",\\n    \\\"wuerde\\\",\\n    \\\"gr\\u00fcnden\\\",\\n]\\nsw = set(list(stop_words) + stop_words_add)\";\n",
       "                var nbb_formatted_code = \"stop_words = set(stopwords.words(\\\"german\\\"))\\nstop_words_add = [\\n    \\\"mal\\\",\\n    \\\"mehr\\\",\\n    \\\"ja\\\",\\n    \\\"schon\\\",\\n    \\\"gibt\\\",\\n    \\\"geht\\\",\\n    \\\"hast\\\",\\n    \\\"einfach\\\",\\n    \\\"ganz\\\",\\n    \\\"macht\\\",\\n    \\\"immer\\\",\\n    \\\"tun\\\",\\n    \\\"viele\\\",\\n    \\\"wer\\\",\\n    \\\"sagen\\\",\\n    \\\"w\\u00e4re\\\",\\n    \\\"genau\\\",\\n    \\\"daf\\u00fcr\\\",\\n    \\\"nat\\u00fcrlich\\\",\\n    \\\"seit\\\",\\n    \\\"wurde\\\",\\n    \\\"eigentlich\\\",\\n    \\\"kommt\\\",\\n    \\\"gesagt\\\",\\n    \\\"sagt\\\",\\n    \\\"nie\\\",\\n    \\\"sehen\\\",\\n    \\\"deren\\\",\\n    \\\"versuchen\\\",\\n    \\\"empfehlen\\\",\\n    \\\"m\\u00fcssen\\\",\\n    \\\"kurz\\\",\\n    \\\"wenig\\\",\\n    \\\"erste\\\",\\n    \\\"klare\\\",\\n    \\\"gar\\\",\\n    \\\"grad\\\",\\n    \\\"wohl\\\",\\n    \\\"oft\\\",\\n    \\\"ha\\\",\\n    \\\"schaffen\\\",\\n    \\\"daher\\\",\\n    \\\"schreibt\\\",\\n    \\\"st\\u00e4ndig\\\",\\n    \\\"v\\u00f6llig\\\",\\n    \\\"verdient\\\",\\n    \\\"worden\\\",\\n    \\\"solange\\\",\\n    \\\"k\\u00f6nnt\\\",\\n    \\\"mann\\\",\\n    \\\"zeigt\\\",\\n    \\\"sp\\u00e4ter\\\",\\n    \\\"erste\\\",\\n    \\\"iwelche\\\",\\n    \\\"wen\\\",\\n    \\\"eigenem\\\",\\n    \\\"gr\\u00fcnden\\\",\\n    \\\"ups\\\",\\n    \\\"irgendjemand\\\",\\n    \\\"wuerde\\\",\\n    \\\"gr\\u00fcnden\\\",\\n]\\nsw = set(list(stop_words) + stop_words_add)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words(\"german\"))\n",
    "stop_words_add = [\n",
    "    \"mal\",\n",
    "    \"mehr\",\n",
    "    \"ja\",\n",
    "    \"schon\",\n",
    "    \"gibt\",\n",
    "    \"geht\",\n",
    "    \"hast\",\n",
    "    \"einfach\",\n",
    "    \"ganz\",\n",
    "    \"macht\",\n",
    "    \"immer\",\n",
    "    \"tun\",\n",
    "    \"viele\",\n",
    "    \"wer\",\n",
    "    \"sagen\",\n",
    "    \"wäre\",\n",
    "    \"genau\",\n",
    "    \"dafür\",\n",
    "    \"natürlich\",\n",
    "    \"seit\",\n",
    "    \"wurde\",\n",
    "    \"eigentlich\",\n",
    "    \"kommt\",\n",
    "    \"gesagt\",\n",
    "    \"sagt\",\n",
    "    \"nie\",\n",
    "    \"sehen\",\n",
    "    \"deren\",\n",
    "    \"versuchen\",\n",
    "    \"empfehlen\",\n",
    "    \"müssen\",\n",
    "    \"kurz\",\n",
    "    \"wenig\",\n",
    "    \"erste\",\n",
    "    \"klare\",\n",
    "    \"gar\",\n",
    "    \"grad\",\n",
    "    \"wohl\",\n",
    "    \"oft\",\n",
    "    \"ha\",\n",
    "    \"schaffen\",\n",
    "    \"daher\",\n",
    "    \"schreibt\",\n",
    "    \"ständig\",\n",
    "    \"völlig\",\n",
    "    \"verdient\",\n",
    "    \"worden\",\n",
    "    \"solange\",\n",
    "    \"könnt\",\n",
    "    \"mann\",\n",
    "    \"zeigt\",\n",
    "    \"später\",\n",
    "    \"erste\",\n",
    "    \"iwelche\",\n",
    "    \"wen\",\n",
    "    \"eigenem\",\n",
    "    \"gründen\",\n",
    "    \"ups\",\n",
    "    \"irgendjemand\",\n",
    "    \"wuerde\",\n",
    "    \"gründen\",\n",
    "]\n",
    "sw = set(list(stop_words) + stop_words_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('2019-05', 131917), ('2019-06', 14823), ('2019-07', 2644), ('2019-08', 2395), ('2019-09', 1875), ('2019-10', 1167), ('2019-11', 1290), ('2019-12', 1370), ('2020-01', 1064), ('2020-02', 1136), ('2020-03', 1039), ('2020-04', 1567), ('2020-05', 1392), ('2020-06', 1859), ('2020-07', 1705), ('2020-08', 2102), ('2020-09', 1843), ('2020-10', 1976), ('2020-11', 2142), ('2020-12', 1510), ('2021-01', 3090), ('2021-02', 8059), ('2021-03', 9025), ('2021-04', 11319), ('2021-05', 6833), ('2021-06', 3285), ('2021-07', 9394), ('2021-08', 1727)]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"corpora_names = [\\n    \\\"2019-05\\\",\\n    \\\"2019-06\\\",\\n    \\\"2019-07\\\",\\n    \\\"2019-08\\\",\\n    \\\"2019-09\\\",\\n    \\\"2019-10\\\",\\n    \\\"2019-11\\\",\\n    \\\"2019-12\\\",\\n    \\\"2020-01\\\",\\n    \\\"2020-02\\\",\\n    \\\"2020-03\\\",\\n    \\\"2020-04\\\",\\n    \\\"2020-05\\\",\\n    \\\"2020-06\\\",\\n    \\\"2020-07\\\",\\n    \\\"2020-08\\\",\\n    \\\"2020-09\\\",\\n    \\\"2020-10\\\",\\n    \\\"2020-11\\\",\\n    \\\"2020-12\\\",\\n    \\\"2021-01\\\",\\n    \\\"2021-02\\\",\\n    \\\"2021-03\\\",\\n    \\\"2021-04\\\",\\n    \\\"2021-05\\\",\\n    \\\"2021-06\\\",\\n    \\\"2021-07\\\",\\n    \\\"2021-08\\\",\\n]\\ncorpora_docs = [\\n    131917,\\n    14823,\\n    2644,\\n    2395,\\n    1875,\\n    1167,\\n    1290,\\n    1370,\\n    1064,\\n    1136,\\n    1039,\\n    1567,\\n    1392,\\n    1859,\\n    1705,\\n    2102,\\n    1843,\\n    1976,\\n    2142,\\n    1510,\\n    3090,\\n    8059,\\n    9025,\\n    11319,\\n    6833,\\n    3285,\\n    9394,\\n    1727,\\n]\\ncorpora_info = list(zip(corpora_names, corpora_docs))\\nprint(corpora_info)\";\n",
       "                var nbb_formatted_code = \"corpora_names = [\\n    \\\"2019-05\\\",\\n    \\\"2019-06\\\",\\n    \\\"2019-07\\\",\\n    \\\"2019-08\\\",\\n    \\\"2019-09\\\",\\n    \\\"2019-10\\\",\\n    \\\"2019-11\\\",\\n    \\\"2019-12\\\",\\n    \\\"2020-01\\\",\\n    \\\"2020-02\\\",\\n    \\\"2020-03\\\",\\n    \\\"2020-04\\\",\\n    \\\"2020-05\\\",\\n    \\\"2020-06\\\",\\n    \\\"2020-07\\\",\\n    \\\"2020-08\\\",\\n    \\\"2020-09\\\",\\n    \\\"2020-10\\\",\\n    \\\"2020-11\\\",\\n    \\\"2020-12\\\",\\n    \\\"2021-01\\\",\\n    \\\"2021-02\\\",\\n    \\\"2021-03\\\",\\n    \\\"2021-04\\\",\\n    \\\"2021-05\\\",\\n    \\\"2021-06\\\",\\n    \\\"2021-07\\\",\\n    \\\"2021-08\\\",\\n]\\ncorpora_docs = [\\n    131917,\\n    14823,\\n    2644,\\n    2395,\\n    1875,\\n    1167,\\n    1290,\\n    1370,\\n    1064,\\n    1136,\\n    1039,\\n    1567,\\n    1392,\\n    1859,\\n    1705,\\n    2102,\\n    1843,\\n    1976,\\n    2142,\\n    1510,\\n    3090,\\n    8059,\\n    9025,\\n    11319,\\n    6833,\\n    3285,\\n    9394,\\n    1727,\\n]\\ncorpora_info = list(zip(corpora_names, corpora_docs))\\nprint(corpora_info)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corpora_names = [\n",
    "    \"2019-05\",\n",
    "    \"2019-06\",\n",
    "    \"2019-07\",\n",
    "    \"2019-08\",\n",
    "    \"2019-09\",\n",
    "    \"2019-10\",\n",
    "    \"2019-11\",\n",
    "    \"2019-12\",\n",
    "    \"2020-01\",\n",
    "    \"2020-02\",\n",
    "    \"2020-03\",\n",
    "    \"2020-04\",\n",
    "    \"2020-05\",\n",
    "    \"2020-06\",\n",
    "    \"2020-07\",\n",
    "    \"2020-08\",\n",
    "    \"2020-09\",\n",
    "    \"2020-10\",\n",
    "    \"2020-11\",\n",
    "    \"2020-12\",\n",
    "    \"2021-01\",\n",
    "    \"2021-02\",\n",
    "    \"2021-03\",\n",
    "    \"2021-04\",\n",
    "    \"2021-05\",\n",
    "    \"2021-06\",\n",
    "    \"2021-07\",\n",
    "    \"2021-08\",\n",
    "]\n",
    "corpora_docs = [\n",
    "    131917,\n",
    "    14823,\n",
    "    2644,\n",
    "    2395,\n",
    "    1875,\n",
    "    1167,\n",
    "    1290,\n",
    "    1370,\n",
    "    1064,\n",
    "    1136,\n",
    "    1039,\n",
    "    1567,\n",
    "    1392,\n",
    "    1859,\n",
    "    1705,\n",
    "    2102,\n",
    "    1843,\n",
    "    1976,\n",
    "    2142,\n",
    "    1510,\n",
    "    3090,\n",
    "    8059,\n",
    "    9025,\n",
    "    11319,\n",
    "    6833,\n",
    "    3285,\n",
    "    9394,\n",
    "    1727,\n",
    "]\n",
    "corpora_info = list(zip(corpora_names, corpora_docs))\n",
    "print(corpora_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>feier sowas endlich jemand alten cdu stimme ni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>achtung faschisten irma lo beleidigt user ganz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zeigt jahre jahre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doppelmoralist rezo eigenes video dezember pri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>richtig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229571</th>\n",
       "      <td>legalisierung mehr fahrverbote läuft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229572</th>\n",
       "      <td>j pepe leg fakten falsche informationen rausha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229573</th>\n",
       "      <td>bundestag stehen abgeordnete mandat halten unt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229574</th>\n",
       "      <td>liebe user lasst daran hindern frei meinung ek...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229575</th>\n",
       "      <td>black ritter widerspreche mal freund rechtspop...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>229576 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  comment\n",
       "0       feier sowas endlich jemand alten cdu stimme ni...\n",
       "1       achtung faschisten irma lo beleidigt user ganz...\n",
       "2                                       zeigt jahre jahre\n",
       "3       doppelmoralist rezo eigenes video dezember pri...\n",
       "4                                                 richtig\n",
       "...                                                   ...\n",
       "229571               legalisierung mehr fahrverbote läuft\n",
       "229572  j pepe leg fakten falsche informationen rausha...\n",
       "229573  bundestag stehen abgeordnete mandat halten unt...\n",
       "229574  liebe user lasst daran hindern frei meinung ek...\n",
       "229575  black ritter widerspreche mal freund rechtspop...\n",
       "\n",
       "[229576 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"corpus = pd.read_pickle(\\\"data/pickle/corpus_clean.pkl\\\")\\ncorpus\";\n",
       "                var nbb_formatted_code = \"corpus = pd.read_pickle(\\\"data/pickle/corpus_clean.pkl\\\")\\ncorpus\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corpus = pd.read_pickle(\"data/pickle/corpus_clean.pkl\")\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"idx = 0\\n# idx_min = 0\\n# idx_max = corpus.shape[0]  # number of rows (documents in corpus)\\ncorpus_d = {}\\n\\nfor i, t in enumerate(corpora_info):\\n    lb = idx\\n    rb = idx + t[1]\\n\\n    corpus_d[t[0]] = {\\n        \\\"len\\\": t[1],\\n        \\\"corpora\\\": pd.DataFrame(data=corpus.iloc[lb:rb]),\\n    }\\n    assert corpus_d[t[0]][\\\"len\\\"] == corpus_d[t[0]][\\\"corpora\\\"].shape[0]\\n    idx += t[1] + 1\";\n",
       "                var nbb_formatted_code = \"idx = 0\\n# idx_min = 0\\n# idx_max = corpus.shape[0]  # number of rows (documents in corpus)\\ncorpus_d = {}\\n\\nfor i, t in enumerate(corpora_info):\\n    lb = idx\\n    rb = idx + t[1]\\n\\n    corpus_d[t[0]] = {\\n        \\\"len\\\": t[1],\\n        \\\"corpora\\\": pd.DataFrame(data=corpus.iloc[lb:rb]),\\n    }\\n    assert corpus_d[t[0]][\\\"len\\\"] == corpus_d[t[0]][\\\"corpora\\\"].shape[0]\\n    idx += t[1] + 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 0\n",
    "# idx_min = 0\n",
    "# idx_max = corpus.shape[0]  # number of rows (documents in corpus)\n",
    "corpus_d = {}\n",
    "\n",
    "for i, t in enumerate(corpora_info):\n",
    "    lb = idx\n",
    "    rb = idx + t[1]\n",
    "\n",
    "    corpus_d[t[0]] = {\n",
    "        \"len\": t[1],\n",
    "        \"corpora\": pd.DataFrame(data=corpus.iloc[lb:rb]),\n",
    "    }\n",
    "    assert corpus_d[t[0]][\"len\"] == corpus_d[t[0]][\"corpora\"].shape[0]\n",
    "    idx += t[1] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "progress: 229500/229548\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"MIN_WORDS = 15\\nMIN_UNIQUE_WORDS = 10\\nprogress = 0\\nprint(\\\"\\\")\\n\\nfor key, value in corpus_d.items():\\n    value[\\\"texts\\\"] = []\\n    doc_to_drop = []\\n\\n    for i in list(value[\\\"corpora\\\"].index):\\n        progress += 1\\n        if len(value[\\\"corpora\\\"].loc[i].comment.split()) < MIN_WORDS:\\n            doc_to_drop.append(i)\\n        elif len(set(value[\\\"corpora\\\"].loc[i].comment.split())) < MIN_UNIQUE_WORDS:\\n            doc_to_drop.append(i)\\n        else:\\n            # (list of list of str) Tokenized texts, needed for coherence models\\n            value[\\\"texts\\\"].append(value[\\\"corpora\\\"].loc[i].comment.split())\\n\\n        if progress % 100 == 0:\\n            print(f\\\"progress: {progress}/{sum(corpora_docs)}\\\", end=\\\"\\\\r\\\")\\n\\n    value[\\\"corpora\\\"] = value[\\\"corpora\\\"].drop(index=doc_to_drop)\\n\\n    d_ = {}\\n    for i, v in enumerate(list(value[\\\"corpora\\\"].index)):\\n        d_[v] = i\\n    value[\\\"corpora\\\"] = value[\\\"corpora\\\"].rename(index=d_)\\n\\nprint(\\\"\\\")\";\n",
       "                var nbb_formatted_code = \"MIN_WORDS = 15\\nMIN_UNIQUE_WORDS = 10\\nprogress = 0\\nprint(\\\"\\\")\\n\\nfor key, value in corpus_d.items():\\n    value[\\\"texts\\\"] = []\\n    doc_to_drop = []\\n\\n    for i in list(value[\\\"corpora\\\"].index):\\n        progress += 1\\n        if len(value[\\\"corpora\\\"].loc[i].comment.split()) < MIN_WORDS:\\n            doc_to_drop.append(i)\\n        elif len(set(value[\\\"corpora\\\"].loc[i].comment.split())) < MIN_UNIQUE_WORDS:\\n            doc_to_drop.append(i)\\n        else:\\n            # (list of list of str) Tokenized texts, needed for coherence models\\n            value[\\\"texts\\\"].append(value[\\\"corpora\\\"].loc[i].comment.split())\\n\\n        if progress % 100 == 0:\\n            print(f\\\"progress: {progress}/{sum(corpora_docs)}\\\", end=\\\"\\\\r\\\")\\n\\n    value[\\\"corpora\\\"] = value[\\\"corpora\\\"].drop(index=doc_to_drop)\\n\\n    d_ = {}\\n    for i, v in enumerate(list(value[\\\"corpora\\\"].index)):\\n        d_[v] = i\\n    value[\\\"corpora\\\"] = value[\\\"corpora\\\"].rename(index=d_)\\n\\nprint(\\\"\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MIN_WORDS = 15\n",
    "MIN_UNIQUE_WORDS = 10\n",
    "progress = 0\n",
    "print(\"\")\n",
    "\n",
    "for key, value in corpus_d.items():\n",
    "    value[\"texts\"] = []\n",
    "    doc_to_drop = []\n",
    "\n",
    "    for i in list(value[\"corpora\"].index):\n",
    "        progress += 1\n",
    "        if len(value[\"corpora\"].loc[i].comment.split()) < MIN_WORDS:\n",
    "            doc_to_drop.append(i)\n",
    "        elif len(set(value[\"corpora\"].loc[i].comment.split())) < MIN_UNIQUE_WORDS:\n",
    "            doc_to_drop.append(i)\n",
    "        else:\n",
    "            # (list of list of str) Tokenized texts, needed for coherence models\n",
    "            value[\"texts\"].append(value[\"corpora\"].loc[i].comment.split())\n",
    "\n",
    "        if progress % 100 == 0:\n",
    "            print(f\"progress: {progress}/{sum(corpora_docs)}\", end=\"\\r\")\n",
    "\n",
    "    value[\"corpora\"] = value[\"corpora\"].drop(index=doc_to_drop)\n",
    "\n",
    "    d_ = {}\n",
    "    for i, v in enumerate(list(value[\"corpora\"].index)):\n",
    "        d_[v] = i\n",
    "    value[\"corpora\"] = value[\"corpora\"].rename(index=d_)\n",
    "\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('2019-05', 50298), ('2019-06', 5416), ('2019-07', 826), ('2019-08', 745), ('2019-09', 591), ('2019-10', 360), ('2019-11', 412), ('2019-12', 445), ('2020-01', 357), ('2020-02', 361), ('2020-03', 375), ('2020-04', 502), ('2020-05', 421), ('2020-06', 600), ('2020-07', 544), ('2020-08', 618), ('2020-09', 581), ('2020-10', 634), ('2020-11', 663), ('2020-12', 468), ('2021-01', 893), ('2021-02', 2542), ('2021-03', 2876), ('2021-04', 3664), ('2021-05', 2138), ('2021-06', 1031), ('2021-07', 2986), ('2021-08', 541)]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"corpora_filtered_info = [\\n    (key, len(value[\\\"corpora\\\"].index)) for key, value in corpus_d.items()\\n]\\nprint(corpora_filtered_info)\";\n",
       "                var nbb_formatted_code = \"corpora_filtered_info = [\\n    (key, len(value[\\\"corpora\\\"].index)) for key, value in corpus_d.items()\\n]\\nprint(corpora_filtered_info)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corpora_filtered_info = [\n",
    "    (key, len(value[\"corpora\"].index)) for key, value in corpus_d.items()\n",
    "]\n",
    "print(corpora_filtered_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2019-05', 0.62),\n",
       " ('2019-06', 0.63),\n",
       " ('2019-07', 0.69),\n",
       " ('2019-08', 0.69),\n",
       " ('2019-09', 0.68),\n",
       " ('2019-10', 0.69),\n",
       " ('2019-11', 0.68),\n",
       " ('2019-12', 0.68),\n",
       " ('2020-01', 0.66),\n",
       " ('2020-02', 0.68),\n",
       " ('2020-03', 0.64),\n",
       " ('2020-04', 0.68),\n",
       " ('2020-05', 0.7),\n",
       " ('2020-06', 0.68),\n",
       " ('2020-07', 0.68),\n",
       " ('2020-08', 0.71),\n",
       " ('2020-09', 0.68),\n",
       " ('2020-10', 0.68),\n",
       " ('2020-11', 0.69),\n",
       " ('2020-12', 0.69),\n",
       " ('2021-01', 0.71),\n",
       " ('2021-02', 0.68),\n",
       " ('2021-03', 0.68),\n",
       " ('2021-04', 0.68),\n",
       " ('2021-05', 0.69),\n",
       " ('2021-06', 0.69),\n",
       " ('2021-07', 0.68),\n",
       " ('2021-08', 0.69)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"corpora_filtered_percentage = [\\n    (x[0][0], (round(1 - (x[0][1] / x[1][1]), 2)))\\n    for x in list(zip(corpora_filtered_info, corpora_info))\\n]\\ncorpora_filtered_percentage\";\n",
       "                var nbb_formatted_code = \"corpora_filtered_percentage = [\\n    (x[0][0], (round(1 - (x[0][1] / x[1][1]), 2)))\\n    for x in list(zip(corpora_filtered_info, corpora_info))\\n]\\ncorpora_filtered_percentage\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corpora_filtered_percentage = [\n",
    "    (x[0][0], (round(1 - (x[0][1] / x[1][1]), 2)))\n",
    "    for x in list(zip(corpora_filtered_info, corpora_info))\n",
    "]\n",
    "corpora_filtered_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min docs: 357\n",
      "max docs: 50298\n",
      "mean docs: 2924.5714285714284\n",
      "median docs: 609.0\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"corpora_filtered_documents_f = [x[1] for x in corpora_filtered_info]\\ncorpora_filtered_documents_min = min(corpora_filtered_documents_f)\\ncorpora_filtered_documents_max = max(corpora_filtered_documents_f)\\ncorpora_filtered_documents_mean = np.mean(corpora_filtered_documents_f)\\ncorpora_filtered_documents_median = np.median(corpora_filtered_documents_f)\\nprint(f\\\"min docs: {corpora_filtered_documents_min}\\\")\\nprint(f\\\"max docs: {corpora_filtered_documents_max}\\\")\\nprint(f\\\"mean docs: {corpora_filtered_documents_mean}\\\")\\nprint(f\\\"median docs: {corpora_filtered_documents_median}\\\")\";\n",
       "                var nbb_formatted_code = \"corpora_filtered_documents_f = [x[1] for x in corpora_filtered_info]\\ncorpora_filtered_documents_min = min(corpora_filtered_documents_f)\\ncorpora_filtered_documents_max = max(corpora_filtered_documents_f)\\ncorpora_filtered_documents_mean = np.mean(corpora_filtered_documents_f)\\ncorpora_filtered_documents_median = np.median(corpora_filtered_documents_f)\\nprint(f\\\"min docs: {corpora_filtered_documents_min}\\\")\\nprint(f\\\"max docs: {corpora_filtered_documents_max}\\\")\\nprint(f\\\"mean docs: {corpora_filtered_documents_mean}\\\")\\nprint(f\\\"median docs: {corpora_filtered_documents_median}\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corpora_filtered_documents_f = [x[1] for x in corpora_filtered_info]\n",
    "corpora_filtered_documents_min = min(corpora_filtered_documents_f)\n",
    "corpora_filtered_documents_max = max(corpora_filtered_documents_f)\n",
    "corpora_filtered_documents_mean = np.mean(corpora_filtered_documents_f)\n",
    "corpora_filtered_documents_median = np.median(corpora_filtered_documents_f)\n",
    "print(f\"min docs: {corpora_filtered_documents_min}\")\n",
    "print(f\"max docs: {corpora_filtered_documents_max}\")\n",
    "print(f\"mean docs: {corpora_filtered_documents_mean}\")\n",
    "print(f\"median docs: {corpora_filtered_documents_median}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"for key, value in corpus_d.items():\\n    value[\\\"tfidf_vectorizer\\\"] = TfidfVectorizer(stop_words=sw)\\n    value[\\\"tfidf_wm\\\"] = value[\\\"tfidf_vectorizer\\\"].fit_transform(\\n        value[\\\"corpora\\\"].comment\\n    )\\n    value[\\\"tfidf\\\"] = pd.DataFrame(\\n        value[\\\"tfidf_wm\\\"].toarray(),\\n        columns=value[\\\"tfidf_vectorizer\\\"].get_feature_names(),\\n    )\\n    value[\\\"tfidf\\\"].index = value[\\\"corpora\\\"].index\\n    value[\\\"tfidf\\\"] = value[\\\"tfidf\\\"].transpose()\";\n",
       "                var nbb_formatted_code = \"for key, value in corpus_d.items():\\n    value[\\\"tfidf_vectorizer\\\"] = TfidfVectorizer(stop_words=sw)\\n    value[\\\"tfidf_wm\\\"] = value[\\\"tfidf_vectorizer\\\"].fit_transform(\\n        value[\\\"corpora\\\"].comment\\n    )\\n    value[\\\"tfidf\\\"] = pd.DataFrame(\\n        value[\\\"tfidf_wm\\\"].toarray(),\\n        columns=value[\\\"tfidf_vectorizer\\\"].get_feature_names(),\\n    )\\n    value[\\\"tfidf\\\"].index = value[\\\"corpora\\\"].index\\n    value[\\\"tfidf\\\"] = value[\\\"tfidf\\\"].transpose()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for key, value in corpus_d.items():\n",
    "    value[\"tfidf_vectorizer\"] = TfidfVectorizer(stop_words=sw)\n",
    "    value[\"tfidf_wm\"] = value[\"tfidf_vectorizer\"].fit_transform(\n",
    "        value[\"corpora\"].comment\n",
    "    )\n",
    "    value[\"tfidf\"] = pd.DataFrame(\n",
    "        value[\"tfidf_wm\"].toarray(),\n",
    "        columns=value[\"tfidf_vectorizer\"].get_feature_names(),\n",
    "    )\n",
    "    value[\"tfidf\"].index = value[\"corpora\"].index\n",
    "    value[\"tfidf\"] = value[\"tfidf\"].transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"for key, value in corpus_d.items():\\n    value[\\\"dictionary\\\"] = Dictionary(value[\\\"texts\\\"])\\n    value[\\\"sparse_counts\\\"] = scipy.sparse.csr_matrix(value[\\\"tfidf\\\"])\\n    value[\\\"corpus_sparse\\\"] = matutils.Sparse2Corpus(value[\\\"sparse_counts\\\"])\\n    value[\\\"id2word\\\"] = dict(\\n        (v, k) for k, v in value[\\\"tfidf_vectorizer\\\"].vocabulary_.items()\\n    )\";\n",
       "                var nbb_formatted_code = \"for key, value in corpus_d.items():\\n    value[\\\"dictionary\\\"] = Dictionary(value[\\\"texts\\\"])\\n    value[\\\"sparse_counts\\\"] = scipy.sparse.csr_matrix(value[\\\"tfidf\\\"])\\n    value[\\\"corpus_sparse\\\"] = matutils.Sparse2Corpus(value[\\\"sparse_counts\\\"])\\n    value[\\\"id2word\\\"] = dict(\\n        (v, k) for k, v in value[\\\"tfidf_vectorizer\\\"].vocabulary_.items()\\n    )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for key, value in corpus_d.items():\n",
    "    value[\"dictionary\"] = Dictionary(value[\"texts\"])\n",
    "    value[\"sparse_counts\"] = scipy.sparse.csr_matrix(value[\"tfidf\"])\n",
    "    value[\"corpus_sparse\"] = matutils.Sparse2Corpus(value[\"sparse_counts\"])\n",
    "    value[\"id2word\"] = dict(\n",
    "        (v, k) for k, v in value[\"tfidf_vectorizer\"].vocabulary_.items()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  evaluate number of topics for each month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "processing: 2021-08\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"start = 4\\nlimit = 20\\nstep = 2\\nprint(\\\"\\\")\\n\\nfor key, value in corpus_d.items():\\n    value[\\\"lda_models\\\"] = []\\n    print(f\\\"processing: {key}\\\", end=\\\"\\\\r\\\")\\n\\n    for num_topics in range(start, limit, step):\\n        # list of tuple of model,coherence\\n        lda_model = models.LdaModel(\\n            corpus=value[\\\"corpus_sparse\\\"],\\n            id2word=value[\\\"id2word\\\"],\\n            num_topics=num_topics,\\n            random_state=100,\\n            update_every=1,\\n            passes=10,\\n            alpha=\\\"auto\\\",\\n        )\\n        coherence_model = CoherenceModel(\\n            model=lda_model,\\n            texts=value[\\\"texts\\\"],\\n            dictionary=value[\\\"dictionary\\\"],\\n        )\\n        value[\\\"lda_models\\\"].append((lda_model, coherence_model.get_coherence()))\\n\\nprint(\\\"\\\")\";\n",
       "                var nbb_formatted_code = \"start = 4\\nlimit = 20\\nstep = 2\\nprint(\\\"\\\")\\n\\nfor key, value in corpus_d.items():\\n    value[\\\"lda_models\\\"] = []\\n    print(f\\\"processing: {key}\\\", end=\\\"\\\\r\\\")\\n\\n    for num_topics in range(start, limit, step):\\n        # list of tuple of model,coherence\\n        lda_model = models.LdaModel(\\n            corpus=value[\\\"corpus_sparse\\\"],\\n            id2word=value[\\\"id2word\\\"],\\n            num_topics=num_topics,\\n            random_state=100,\\n            update_every=1,\\n            passes=10,\\n            alpha=\\\"auto\\\",\\n        )\\n        coherence_model = CoherenceModel(\\n            model=lda_model,\\n            texts=value[\\\"texts\\\"],\\n            dictionary=value[\\\"dictionary\\\"],\\n        )\\n        value[\\\"lda_models\\\"].append((lda_model, coherence_model.get_coherence()))\\n\\nprint(\\\"\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = 4\n",
    "limit = 20\n",
    "step = 2\n",
    "print(\"\")\n",
    "\n",
    "for key, value in corpus_d.items():\n",
    "    value[\"lda_models\"] = []\n",
    "    print(f\"processing: {key}\", end=\"\\r\")\n",
    "\n",
    "    for num_topics in range(start, limit, step):\n",
    "        # list of tuple of model,coherence\n",
    "        lda_model = models.LdaModel(\n",
    "            corpus=value[\"corpus_sparse\"],\n",
    "            id2word=value[\"id2word\"],\n",
    "            num_topics=num_topics,\n",
    "            random_state=100,\n",
    "            update_every=1,\n",
    "            passes=10,\n",
    "            alpha=\"auto\",\n",
    "        )\n",
    "        coherence_model = CoherenceModel(\n",
    "            model=lda_model,\n",
    "            texts=value[\"texts\"],\n",
    "            dictionary=value[\"dictionary\"],\n",
    "        )\n",
    "        value[\"lda_models\"].append((lda_model, coherence_model.get_coherence()))\n",
    "\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 2019-05\n",
      "[('4 Topics', 0.7784599159828105), ('6 Topics', 0.7624027296574655), ('8 Topics', 0.7538501407716326), ('10 Topics', 0.7482827332737104), ('12 Topics', 0.7567082498102687), ('14 Topics', 0.7422013578009288), ('16 Topics', 0.7409633593788693), ('18 Topics', 0.7369976727135255)]\n",
      "\n",
      "\n",
      "\n",
      "## 2019-06\n",
      "[('4 Topics', 0.755400552579629), ('6 Topics', 0.7604638355505572), ('8 Topics', 0.7639319848363995), ('10 Topics', 0.7539145784465456), ('12 Topics', 0.7595723058034989), ('14 Topics', 0.7644022868554898), ('16 Topics', 0.7529547631068527), ('18 Topics', 0.7625133466710894)]\n",
      "\n",
      "\n",
      "\n",
      "## 2019-07\n",
      "[('4 Topics', 0.7824250061371096), ('6 Topics', 0.7747290541847268), ('8 Topics', 0.7718374638167718), ('10 Topics', 0.7703084361414156), ('12 Topics', 0.7756480296626996), ('14 Topics', 0.7686225239844734), ('16 Topics', 0.7649623466467275), ('18 Topics', 0.7676424669556547)]\n",
      "\n",
      "\n",
      "\n",
      "## 2019-08\n",
      "[('4 Topics', 0.807343283587483), ('6 Topics', 0.8014740802944673), ('8 Topics', 0.8026387157876548), ('10 Topics', 0.7989335392446725), ('12 Topics', 0.7971896617091954), ('14 Topics', 0.7948706738062022), ('16 Topics', 0.7927050182520576), ('18 Topics', 0.7872532332013757)]\n",
      "\n",
      "\n",
      "\n",
      "## 2019-09\n",
      "[('4 Topics', 0.7741906438213518), ('6 Topics', 0.789107812352575), ('8 Topics', 0.7850299910869332), ('10 Topics', 0.7863978460344937), ('12 Topics', 0.7842042266059122), ('14 Topics', 0.7825007959771854), ('16 Topics', 0.7819858911974832), ('18 Topics', 0.7800363363045988)]\n",
      "\n",
      "\n",
      "\n",
      "## 2019-10\n",
      "[('4 Topics', 0.7980452858167555), ('6 Topics', 0.7840921658896987), ('8 Topics', 0.7830121545492242), ('10 Topics', 0.785658908169591), ('12 Topics', 0.7778425918855826), ('14 Topics', 0.7801497467461495), ('16 Topics', 0.7696218198159839), ('18 Topics', 0.7870365985312643)]\n",
      "\n",
      "\n",
      "\n",
      "## 2019-11\n",
      "[('4 Topics', 0.795320930933233), ('6 Topics', 0.7808203323603996), ('8 Topics', 0.7882739861080776), ('10 Topics', 0.7900508767385321), ('12 Topics', 0.7894145898415443), ('14 Topics', 0.7917763886266078), ('16 Topics', 0.7902854142954343), ('18 Topics', 0.7877768770857853)]\n",
      "\n",
      "\n",
      "\n",
      "## 2019-12\n",
      "[('4 Topics', 0.7934091544971216), ('6 Topics', 0.7931469452864772), ('8 Topics', 0.8040753880855329), ('10 Topics', 0.7895367175495529), ('12 Topics', 0.7921648028066173), ('14 Topics', 0.7897461151255445), ('16 Topics', 0.7875293146431593), ('18 Topics', 0.7920364980912221)]\n",
      "\n",
      "\n",
      "\n",
      "## 2020-01\n",
      "[('4 Topics', 0.8016539059701929), ('6 Topics', 0.7838171960027513), ('8 Topics', 0.7951321040068811), ('10 Topics', 0.7813341931033146), ('12 Topics', 0.7941255518337232), ('14 Topics', 0.7849540969649326), ('16 Topics', 0.7938710721583464), ('18 Topics', 0.7917304881407765)]\n",
      "\n",
      "\n",
      "\n",
      "## 2020-02\n",
      "[('4 Topics', 0.8233715951489471), ('6 Topics', 0.8034504749781298), ('8 Topics', 0.810278755891862), ('10 Topics', 0.802793116975667), ('12 Topics', 0.7998338047128822), ('14 Topics', 0.8046346905980133), ('16 Topics', 0.7994803178857697), ('18 Topics', 0.7981153046291383)]\n",
      "\n",
      "\n",
      "\n",
      "## 2020-03\n",
      "[('4 Topics', 0.7616859840430491), ('6 Topics', 0.7837209909691777), ('8 Topics', 0.7734293205377498), ('10 Topics', 0.7708113007887681), ('12 Topics', 0.78192767908802), ('14 Topics', 0.7868903610697586), ('16 Topics', 0.7815508862395715), ('18 Topics', 0.7682807744947809)]\n",
      "\n",
      "\n",
      "\n",
      "## 2020-04\n",
      "[('4 Topics', 0.8006558791067662), ('6 Topics', 0.7985037444538753), ('8 Topics', 0.7842819161236574), ('10 Topics', 0.7992218955535711), ('12 Topics', 0.7837205220826945), ('14 Topics', 0.7871921913637597), ('16 Topics', 0.7920140519304004), ('18 Topics', 0.7900819709031901)]\n",
      "\n",
      "\n",
      "\n",
      "## 2020-05\n",
      "[('4 Topics', 0.7826140011823469), ('6 Topics', 0.7783451866574483), ('8 Topics', 0.7875571205064611), ('10 Topics', 0.7885925353560453), ('12 Topics', 0.7816771861293925), ('14 Topics', 0.7754107706689869), ('16 Topics', 0.7831562603856768), ('18 Topics', 0.7764685715937325)]\n",
      "\n",
      "\n",
      "\n",
      "## 2020-06\n",
      "[('4 Topics', 0.8064575583529004), ('6 Topics', 0.8006984654339875), ('8 Topics', 0.7956659090519039), ('10 Topics', 0.7888117258627794), ('12 Topics', 0.793841691498509), ('14 Topics', 0.7885630178970245), ('16 Topics', 0.7889816368910343), ('18 Topics', 0.7910038383607189)]\n",
      "\n",
      "\n",
      "\n",
      "## 2020-07\n",
      "[('4 Topics', 0.7827968245468819), ('6 Topics', 0.758579389185495), ('8 Topics', 0.7699266942343428), ('10 Topics', 0.7656214779063599), ('12 Topics', 0.7679645575895723), ('14 Topics', 0.784859127773749), ('16 Topics', 0.7690411308101711), ('18 Topics', 0.7783651684651556)]\n",
      "\n",
      "\n",
      "\n",
      "## 2020-08\n",
      "[('4 Topics', 0.8112649674960417), ('6 Topics', 0.7992984943412695), ('8 Topics', 0.7820313416984813), ('10 Topics', 0.7888676930861898), ('12 Topics', 0.7859622286217484), ('14 Topics', 0.7872486732310211), ('16 Topics', 0.7849964246218907), ('18 Topics', 0.7728620050715572)]\n",
      "\n",
      "\n",
      "\n",
      "## 2020-09\n",
      "[('4 Topics', 0.8056557414738404), ('6 Topics', 0.8023773857692542), ('8 Topics', 0.7999341091383096), ('10 Topics', 0.8069997197974954), ('12 Topics', 0.7959679713404492), ('14 Topics', 0.7994462354594957), ('16 Topics', 0.7957403305625839), ('18 Topics', 0.790434719102051)]\n",
      "\n",
      "\n",
      "\n",
      "## 2020-10\n",
      "[('4 Topics', 0.7660626292343244), ('6 Topics', 0.7658187047036704), ('8 Topics', 0.7713746446244456), ('10 Topics', 0.7737964345929518), ('12 Topics', 0.7654164021633455), ('14 Topics', 0.7770155666565027), ('16 Topics', 0.7736121665105076), ('18 Topics', 0.7707391985553834)]\n",
      "\n",
      "\n",
      "\n",
      "## 2020-11\n",
      "[('4 Topics', 0.7823927745973234), ('6 Topics', 0.7948259473277961), ('8 Topics', 0.7909834539344096), ('10 Topics', 0.7883968001550983), ('12 Topics', 0.7868132940928315), ('14 Topics', 0.7896722326050506), ('16 Topics', 0.7868862744587761), ('18 Topics', 0.7776105648510209)]\n",
      "\n",
      "\n",
      "\n",
      "## 2020-12\n",
      "[('4 Topics', 0.812529080172667), ('6 Topics', 0.8060177569936804), ('8 Topics', 0.8094797705144077), ('10 Topics', 0.7984818536574644), ('12 Topics', 0.7998175298222371), ('14 Topics', 0.7870803589451263), ('16 Topics', 0.7821620231709658), ('18 Topics', 0.7892200885903052)]\n",
      "\n",
      "\n",
      "\n",
      "## 2021-01\n",
      "[('4 Topics', 0.8036756093680203), ('6 Topics', 0.7997578587428685), ('8 Topics', 0.7813830489851572), ('10 Topics', 0.7825545954601482), ('12 Topics', 0.7807378879331396), ('14 Topics', 0.7749174753886824), ('16 Topics', 0.7792548262644723), ('18 Topics', 0.7800472970308374)]\n",
      "\n",
      "\n",
      "\n",
      "## 2021-02\n",
      "[('4 Topics', 0.7758654980040327), ('6 Topics', 0.7757164103709074), ('8 Topics', 0.7770067446044354), ('10 Topics', 0.7698129321540248), ('12 Topics', 0.766671597597583), ('14 Topics', 0.7684837102730295), ('16 Topics', 0.7790533694895352), ('18 Topics', 0.7639959536863489)]\n",
      "\n",
      "\n",
      "\n",
      "## 2021-03\n",
      "[('4 Topics', 0.7789171872747761), ('6 Topics', 0.7821998843415966), ('8 Topics', 0.7661431415886095), ('10 Topics', 0.7616145174970029), ('12 Topics', 0.7719598844675136), ('14 Topics', 0.7646741566321882), ('16 Topics', 0.7673347606322312), ('18 Topics', 0.7721198969448426)]\n",
      "\n",
      "\n",
      "\n",
      "## 2021-04\n",
      "[('4 Topics', 0.7661272407357788), ('6 Topics', 0.774933521464221), ('8 Topics', 0.7629061886488997), ('10 Topics', 0.7736846386955791), ('12 Topics', 0.7526898346720982), ('14 Topics', 0.7631688079631912), ('16 Topics', 0.753480573934512), ('18 Topics', 0.7532142007869438)]\n",
      "\n",
      "\n",
      "\n",
      "## 2021-05\n",
      "[('4 Topics', 0.8000039601760731), ('6 Topics', 0.7779261986880844), ('8 Topics', 0.7874238844459001), ('10 Topics', 0.7767661237472765), ('12 Topics', 0.7727940324115972), ('14 Topics', 0.7773743511484238), ('16 Topics', 0.7785937655339732), ('18 Topics', 0.7736950361165669)]\n",
      "\n",
      "\n",
      "\n",
      "## 2021-06\n",
      "[('4 Topics', 0.820006524537575), ('6 Topics', 0.8047320012803917), ('8 Topics', 0.7869850088156198), ('10 Topics', 0.7872942987516173), ('12 Topics', 0.7928964580032695), ('14 Topics', 0.7827515930475933), ('16 Topics', 0.7870834065829173), ('18 Topics', 0.7803987332425991)]\n",
      "\n",
      "\n",
      "\n",
      "## 2021-07\n",
      "[('4 Topics', 0.7697345315812782), ('6 Topics', 0.7654239217578965), ('8 Topics', 0.7674577928982601), ('10 Topics', 0.7673694736939493), ('12 Topics', 0.7651257736990705), ('14 Topics', 0.7622052912980973), ('16 Topics', 0.7565015619727311), ('18 Topics', 0.760989512465978)]\n",
      "\n",
      "\n",
      "\n",
      "## 2021-08\n",
      "[('4 Topics', 0.792545012887831), ('6 Topics', 0.794818149324653), ('8 Topics', 0.7836866697585623), ('10 Topics', 0.7865007139805111), ('12 Topics', 0.7856909785117171), ('14 Topics', 0.7855713578229844), ('16 Topics', 0.787128829279988), ('18 Topics', 0.7844200674616671)]\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"for key, value in corpus_d.items():\\n    print(f'## {key}')\\n    lda_coherence_values = [x[1] for x in value[\\\"lda_models\\\"]]\\n    num_topics_lda = list(range(4, 20, 2))\\n    \\n    assert len(num_topics_lda)==len(lda_coherence_values)\\n    \\n    print(list(zip([str(x)+\\\" Topics\\\" for x in num_topics_lda],lda_coherence_values)))\\n    print(\\\"\\\\n\\\\n\\\")\\n    \";\n",
       "                var nbb_formatted_code = \"for key, value in corpus_d.items():\\n    print(f\\\"## {key}\\\")\\n    lda_coherence_values = [x[1] for x in value[\\\"lda_models\\\"]]\\n    num_topics_lda = list(range(4, 20, 2))\\n\\n    assert len(num_topics_lda) == len(lda_coherence_values)\\n\\n    print(list(zip([str(x) + \\\" Topics\\\" for x in num_topics_lda], lda_coherence_values)))\\n    print(\\\"\\\\n\\\\n\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for key, value in corpus_d.items():\n",
    "    print(f\"## {key}\")\n",
    "    lda_coherence_values = [x[1] for x in value[\"lda_models\"]]\n",
    "    num_topics_lda = list(range(4, 20, 2))\n",
    "\n",
    "    assert len(num_topics_lda) == len(lda_coherence_values)\n",
    "\n",
    "    print(list(zip([str(x) + \" Topics\" for x in num_topics_lda], lda_coherence_values)))\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inteprete: top 10 keywords -> topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"# get best' 28 models out of 224 (28 months, each 8 lda models (4,6,8,10,12,14,16,18 topics))\\nnum_topics_evaluated_lda = [None] * 28\\nnum_topics_evaluated_lda[0] = 4 # 2019-05\\nnum_topics_evaluated_lda[1] = 8 # 2019-06\\nnum_topics_evaluated_lda[2] = 4 # 2019-07\\nnum_topics_evaluated_lda[3] = 4 # 2019-08\\nnum_topics_evaluated_lda[4] = 10 # 2019-09\\nnum_topics_evaluated_lda[5] = 4 # 2019-10\\nnum_topics_evaluated_lda[6] = 4 # 2019-11\\nnum_topics_evaluated_lda[7] = 8 # 2019-12\\nnum_topics_evaluated_lda[8] = 4 # 2020-01\\nnum_topics_evaluated_lda[9] = 4 # 2020-02\\nnum_topics_evaluated_lda[10] = 6 # 2020-03\\nnum_topics_evaluated_lda[11] = 4 # 2020-04\\nnum_topics_evaluated_lda[12] = 10 # 2020-05\\nnum_topics_evaluated_lda[13] = 4 # 2020-06\\nnum_topics_evaluated_lda[14] = 14 # 2020-07\\nnum_topics_evaluated_lda[15] = 4 # 2020-08\\nnum_topics_evaluated_lda[16] = 4 # 2020-09\\nnum_topics_evaluated_lda[17] = 14 # 2020-10\\nnum_topics_evaluated_lda[18] = 6 # 2020-11\\nnum_topics_evaluated_lda[19] = 4 # 2020-12\\nnum_topics_evaluated_lda[20] = 4 # 2021-01\\nnum_topics_evaluated_lda[21] = 8 # 2021-02\\nnum_topics_evaluated_lda[22] = 6 # 2021-03\\nnum_topics_evaluated_lda[23] = 6 # 2021-04\\nnum_topics_evaluated_lda[24] = 4 # 2021-05\\nnum_topics_evaluated_lda[25] = 4 # 2021-06\\nnum_topics_evaluated_lda[26] = 4 # 2021-07\\nnum_topics_evaluated_lda[27] = 6 # 2021-08\";\n",
       "                var nbb_formatted_code = \"# get best' 28 models out of 224 (28 months, each 8 lda models (4,6,8,10,12,14,16,18 topics))\\nnum_topics_evaluated_lda = [None] * 28\\nnum_topics_evaluated_lda[0] = 4  # 2019-05\\nnum_topics_evaluated_lda[1] = 8  # 2019-06\\nnum_topics_evaluated_lda[2] = 4  # 2019-07\\nnum_topics_evaluated_lda[3] = 4  # 2019-08\\nnum_topics_evaluated_lda[4] = 10  # 2019-09\\nnum_topics_evaluated_lda[5] = 4  # 2019-10\\nnum_topics_evaluated_lda[6] = 4  # 2019-11\\nnum_topics_evaluated_lda[7] = 8  # 2019-12\\nnum_topics_evaluated_lda[8] = 4  # 2020-01\\nnum_topics_evaluated_lda[9] = 4  # 2020-02\\nnum_topics_evaluated_lda[10] = 6  # 2020-03\\nnum_topics_evaluated_lda[11] = 4  # 2020-04\\nnum_topics_evaluated_lda[12] = 10  # 2020-05\\nnum_topics_evaluated_lda[13] = 4  # 2020-06\\nnum_topics_evaluated_lda[14] = 14  # 2020-07\\nnum_topics_evaluated_lda[15] = 4  # 2020-08\\nnum_topics_evaluated_lda[16] = 4  # 2020-09\\nnum_topics_evaluated_lda[17] = 14  # 2020-10\\nnum_topics_evaluated_lda[18] = 6  # 2020-11\\nnum_topics_evaluated_lda[19] = 4  # 2020-12\\nnum_topics_evaluated_lda[20] = 4  # 2021-01\\nnum_topics_evaluated_lda[21] = 8  # 2021-02\\nnum_topics_evaluated_lda[22] = 6  # 2021-03\\nnum_topics_evaluated_lda[23] = 6  # 2021-04\\nnum_topics_evaluated_lda[24] = 4  # 2021-05\\nnum_topics_evaluated_lda[25] = 4  # 2021-06\\nnum_topics_evaluated_lda[26] = 4  # 2021-07\\nnum_topics_evaluated_lda[27] = 6  # 2021-08\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get best' 28 models out of 224 (28 months, each 8 lda models (4,6,8,10,12,14,16,18 topics))\n",
    "num_topics_evaluated_lda = [None] * 28\n",
    "num_topics_evaluated_lda[0] = 4 # 2019-05\n",
    "num_topics_evaluated_lda[1] = 8 # 2019-06\n",
    "num_topics_evaluated_lda[2] = 4 # 2019-07\n",
    "num_topics_evaluated_lda[3] = 4 # 2019-08\n",
    "num_topics_evaluated_lda[4] = 10 # 2019-09\n",
    "num_topics_evaluated_lda[5] = 4 # 2019-10\n",
    "num_topics_evaluated_lda[6] = 4 # 2019-11\n",
    "num_topics_evaluated_lda[7] = 8 # 2019-12\n",
    "num_topics_evaluated_lda[8] = 4 # 2020-01\n",
    "num_topics_evaluated_lda[9] = 4 # 2020-02\n",
    "num_topics_evaluated_lda[10] = 6 # 2020-03\n",
    "num_topics_evaluated_lda[11] = 4 # 2020-04\n",
    "num_topics_evaluated_lda[12] = 10 # 2020-05\n",
    "num_topics_evaluated_lda[13] = 4 # 2020-06\n",
    "num_topics_evaluated_lda[14] = 14 # 2020-07\n",
    "num_topics_evaluated_lda[15] = 4 # 2020-08\n",
    "num_topics_evaluated_lda[16] = 4 # 2020-09\n",
    "num_topics_evaluated_lda[17] = 14 # 2020-10\n",
    "num_topics_evaluated_lda[18] = 6 # 2020-11\n",
    "num_topics_evaluated_lda[19] = 4 # 2020-12\n",
    "num_topics_evaluated_lda[20] = 4 # 2021-01\n",
    "num_topics_evaluated_lda[21] = 8 # 2021-02\n",
    "num_topics_evaluated_lda[22] = 6 # 2021-03\n",
    "num_topics_evaluated_lda[23] = 6 # 2021-04\n",
    "num_topics_evaluated_lda[24] = 4 # 2021-05\n",
    "num_topics_evaluated_lda[25] = 4 # 2021-06\n",
    "num_topics_evaluated_lda[26] = 4 # 2021-07\n",
    "num_topics_evaluated_lda[27] = 6 # 2021-08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nr topics mean: 5.928571428571429\n",
      "nr topics median: 4.0\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 57;\n",
       "                var nbb_unformatted_code = \"print(f'nr topics mean: {np.mean(num_topics_evaluated_lda)}')\\nprint(f'nr topics median: {np.median(num_topics_evaluated_lda)}')\";\n",
       "                var nbb_formatted_code = \"print(f\\\"nr topics mean: {np.mean(num_topics_evaluated_lda)}\\\")\\nprint(f\\\"nr topics median: {np.median(num_topics_evaluated_lda)}\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"nr topics mean: {np.mean(num_topics_evaluated_lda)}\")\n",
    "print(f\"nr topics median: {np.median(num_topics_evaluated_lda)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 2019-05 | 4 Topics | coherence 0.7784599159828105\n",
      "\n",
      "### Topic: 1 | weights_mean: 0.0142\n",
      "[('zitat ', 0.022), ('grünen ', 0.018), ('beleidigen ', 0.014), ('lügen ', 0.014), ('linker ', 0.014), ('unterstellen ', 0.012), ('striegel ', 0.012), ('volkstod ', 0.012), ('sebastian ', 0.012), ('zuwanderung', 0.012)] \n",
      "\n",
      "### Topic: 2 | weights_mean: 0.0137\n",
      "[('maniac ', 0.017), ('lügen ', 0.017), ('unterstellungen ', 0.016), ('beleidigungen ', 0.015), ('gollum ', 0.014), ('cordes ', 0.013), ('axel ', 0.013), ('stefan ', 0.011), ('faschisten ', 0.011), ('lo', 0.01)] \n",
      "\n",
      "### Topic: 3 | weights_mean: 0.0038\n",
      "[('video ', 0.007), ('cdu ', 0.005), ('afd ', 0.005), ('wählen ', 0.003), ('politik ', 0.003), ('rezo ', 0.003), ('partei ', 0.003), ('gut ', 0.003), ('menschen ', 0.003), ('danke', 0.003)] \n",
      "\n",
      "### Topic: 4 | weights_mean: 0.019\n",
      "[('coronaregeln ', 0.019), ('abstandsregeln ', 0.019), ('couch ', 0.019), ('geltenden ', 0.019), ('maskenpflicht ', 0.019), ('gespielt ', 0.019), ('privat ', 0.019), ('eingehalten ', 0.019), ('bezeichnen ', 0.019), ('freunden', 0.019)] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## 2019-06 | 8 Topics | coherence 0.7639319848363995\n",
      "\n",
      "### Topic: 1 | weights_mean: 0.0041\n",
      "[('video ', 0.007), ('cdu ', 0.005), ('afd ', 0.005), ('partei ', 0.004), ('menschen ', 0.004), ('gut ', 0.004), ('wählen ', 0.003), ('grünen ', 0.003), ('deutschland ', 0.003), ('meinung', 0.003)] \n",
      "\n",
      "### Topic: 2 | weights_mean: 0.0038\n",
      "[('volksverpetzer ', 0.006), ('reich ', 0.005), ('hetze ', 0.004), ('fakenews ', 0.004), ('netz ', 0.004), ('armer ', 0.003), ('kommunismus ', 0.003), ('neidisch ', 0.003), ('vadda ', 0.003), ('mudda', 0.003)] \n",
      "\n",
      "### Topic: 3 | weights_mean: 0.0079\n",
      "[('zitat ', 0.014), ('grünen ', 0.009), ('terror ', 0.007), ('wünschte ', 0.007), ('volkstod ', 0.007), ('weltkrieg ', 0.007), ('geistige ', 0.007), ('zuwanderung ', 0.007), ('sebastian ', 0.007), ('striegel', 0.007)] \n",
      "\n",
      "### Topic: 4 | weights_mean: 0.0055\n",
      "[('werner ', 0.006), ('lena ', 0.006), ('vogel ', 0.006), ('anna ', 0.006), ('faschistischen ', 0.006), ('bedanken ', 0.005), ('usern ', 0.005), ('legion ', 0.005), ('massiven ', 0.005), ('zuspammen', 0.005)] \n",
      "\n",
      "### Topic: 5 | weights_mean: 0.0051\n",
      "[('grünen ', 0.006), ('männerfeindlichen ', 0.005), ('offiziell ', 0.005), ('gewählte ', 0.005), ('räumt ', 0.005), ('spitzenkandidat ', 0.005), ('saarland ', 0.005), ('fordern ', 0.005), ('antidemokratischen ', 0.005), ('männerfeindlich', 0.005)] \n",
      "\n",
      "### Topic: 6 | weights_mean: 0.0054\n",
      "[('zusammen ', 0.006), ('zwei ', 0.006), ('kleinen ', 0.006), ('rezo ', 0.006), ('läuft ', 0.005), ('idioten ', 0.005), ('gesetzt ', 0.005), ('bezeichnen ', 0.005), ('heutzutage ', 0.005), ('spiel', 0.005)] \n",
      "\n",
      "### Topic: 7 | weights_mean: 0.0065\n",
      "[('lügen ', 0.009), ('lo ', 0.007), ('faschisten ', 0.007), ('achtung ', 0.007), ('unterstellungen ', 0.007), ('faschist ', 0.006), ('beleidigungen ', 0.006), ('irma ', 0.006), ('gespammt ', 0.005), ('user', 0.005)] \n",
      "\n",
      "### Topic: 8 | weights_mean: 0.0068\n",
      "[('maniac ', 0.009), ('fanboysgirls ', 0.008), ('andersdenkenden ', 0.007), ('verkommen ', 0.007), ('hindern ', 0.007), ('beleidigen ', 0.006), ('ekelhaften ', 0.006), ('widerlich ', 0.006), ('frei ', 0.006), ('user', 0.006)] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## 2019-07 | 4 Topics | coherence 0.7824250061371096\n",
      "\n",
      "### Topic: 1 | weights_mean: 0.0012\n",
      "[('afd ', 0.002), ('video ', 0.002), ('cdu ', 0.001), ('deutschland ', 0.001), ('meinung ', 0.001), ('partei ', 0.001), ('grünen ', 0.001), ('parteien ', 0.001), ('leider ', 0.001), ('menschen', 0.001)] \n",
      "\n",
      "### Topic: 2 | weights_mean: 0.0012\n",
      "[('rezo ', 0.002), ('grünen ', 0.002), ('menschen ', 0.001), ('video ', 0.001), ('welt ', 0.001), ('afd ', 0.001), ('gut ', 0.001), ('meinung ', 0.001), ('fakten ', 0.001), ('besser', 0.001)] \n",
      "\n",
      "### Topic: 3 | weights_mean: 0.0011\n",
      "[('video ', 0.002), ('rezo ', 0.001), ('cdu ', 0.001), ('deutschland ', 0.001), ('afd ', 0.001), ('menschen ', 0.001), ('klimawandel ', 0.001), ('gut ', 0.001), ('jahren ', 0.001), ('wählen', 0.001)] \n",
      "\n",
      "### Topic: 4 | weights_mean: 0.0011\n",
      "[('video ', 0.002), ('menschen ', 0.001), ('grünen ', 0.001), ('partei ', 0.001), ('rezo ', 0.001), ('cdu ', 0.001), ('politik ', 0.001), ('gut ', 0.001), ('kannst ', 0.001), ('bitte', 0.001)] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## 2019-08 | 4 Topics | coherence 0.807343283587483\n",
      "\n",
      "### Topic: 1 | weights_mean: 0.0011\n",
      "[('afd ', 0.002), ('video ', 0.001), ('grünen ', 0.001), ('rezo ', 0.001), ('klar ', 0.001), ('meinung ', 0.001), ('partei ', 0.001), ('cdu ', 0.001), ('parteien ', 0.001), ('kannst', 0.001)] \n",
      "\n",
      "### Topic: 2 | weights_mean: 0.0012\n",
      "[('video ', 0.002), ('rezo ', 0.002), ('meinung ', 0.001), ('menschen ', 0.001), ('jahren ', 0.001), ('partei ', 0.001), ('afd ', 0.001), ('cdu ', 0.001), ('warum ', 0.001), ('wählen', 0.001)] \n",
      "\n",
      "### Topic: 3 | weights_mean: 0.0011\n",
      "[('cdu ', 0.002), ('wählen ', 0.001), ('deutschland ', 0.001), ('video ', 0.001), ('rezo ', 0.001), ('afd ', 0.001), ('grünen ', 0.001), ('menschen ', 0.001), ('meinung ', 0.001), ('warum', 0.001)] \n",
      "\n",
      "### Topic: 4 | weights_mean: 0.0011\n",
      "[('afd ', 0.002), ('video ', 0.001), ('menschen ', 0.001), ('grünen ', 0.001), ('deutschland ', 0.001), ('cdu ', 0.001), ('rezo ', 0.001), ('politik ', 0.001), ('klimawandel ', 0.001), ('wählen', 0.001)] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## 2019-09 | 10 Topics | coherence 0.7863978460344937\n",
      "\n",
      "### Topic: 1 | weights_mean: 0.0013\n",
      "[('rezo ', 0.002), ('video ', 0.002), ('besser ', 0.002), ('meinung ', 0.001), ('cdu ', 0.001), ('politik ', 0.001), ('menschen ', 0.001), ('fakten ', 0.001), ('kannst ', 0.001), ('parteien', 0.001)] \n",
      "\n",
      "### Topic: 2 | weights_mean: 0.0014\n",
      "[('partei ', 0.002), ('meinung ', 0.002), ('video ', 0.002), ('lügen ', 0.002), ('parteien ', 0.001), ('politik ', 0.001), ('afd ', 0.001), ('fast ', 0.001), ('gut ', 0.001), ('quellen', 0.001)] \n",
      "\n",
      "### Topic: 3 | weights_mean: 0.0013\n",
      "[('video ', 0.002), ('wählen ', 0.002), ('rezo ', 0.002), ('quellen ', 0.001), ('gut ', 0.001), ('cdu ', 0.001), ('menschen ', 0.001), ('leute ', 0.001), ('grünen ', 0.001), ('deutschland', 0.001)] \n",
      "\n",
      "### Topic: 4 | weights_mean: 0.0016\n",
      "[('grünen ', 0.003), ('parteien ', 0.002), ('afd ', 0.002), ('video ', 0.002), ('partei ', 0.002), ('saarland ', 0.001), ('räumt ', 0.001), ('männerfeindlichen ', 0.001), ('antidemokratischen ', 0.001), ('spitzenkandidat', 0.001)] \n",
      "\n",
      "### Topic: 5 | weights_mean: 0.0013\n",
      "[('grünen ', 0.002), ('video ', 0.002), ('afd ', 0.002), ('meinung ', 0.001), ('partei ', 0.001), ('deutschland ', 0.001), ('gut ', 0.001), ('politik ', 0.001), ('egal ', 0.001), ('besser', 0.001)] \n",
      "\n",
      "### Topic: 6 | weights_mean: 0.001\n",
      "[('cdu ', 0.001), ('afd ', 0.001), ('politik ', 0.001), ('nein ', 0.001), ('klar ', 0.001), ('trotzdem ', 0.001), ('ersten ', 0.001), ('zukunft ', 0.001), ('video ', 0.001), ('leute', 0.001)] \n",
      "\n",
      "### Topic: 7 | weights_mean: 0.0015\n",
      "[('leute ', 0.002), ('partei ', 0.002), ('zitat ', 0.002), ('deutschland ', 0.002), ('afd ', 0.002), ('menschen ', 0.001), ('wünschte ', 0.001), ('grünen ', 0.001), ('wahrheit ', 0.001), ('land', 0.001)] \n",
      "\n",
      "### Topic: 8 | weights_mean: 0.0011\n",
      "[('rezo ', 0.002), ('klar ', 0.001), ('partei ', 0.001), ('klima ', 0.001), ('video ', 0.001), ('millionen ', 0.001), ('überhaupt ', 0.001), ('klimawandel ', 0.001), ('grünen ', 0.001), ('sprache', 0.001)] \n",
      "\n",
      "### Topic: 9 | weights_mean: 0.0013\n",
      "[('vielleicht ', 0.002), ('video ', 0.002), ('cdu ', 0.002), ('erst ', 0.001), ('partei ', 0.001), ('kannst ', 0.001), ('thema ', 0.001), ('widerlegen ', 0.001), ('welt ', 0.001), ('afd', 0.001)] \n",
      "\n",
      "### Topic: 10 | weights_mean: 0.0012\n",
      "[('cdu ', 0.002), ('video ', 0.002), ('deutschland ', 0.001), ('meinung ', 0.001), ('vielleicht ', 0.001), ('menschen ', 0.001), ('gut ', 0.001), ('afd ', 0.001), ('geistige ', 0.001), ('müll', 0.001)] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## 2019-10 | 4 Topics | coherence 0.7980452858167555\n",
      "\n",
      "### Topic: 1 | weights_mean: 0.0012\n",
      "[('grünen ', 0.002), ('menschen ', 0.002), ('afd ', 0.001), ('deutschland ', 0.001), ('partei ', 0.001), ('video ', 0.001), ('rezo ', 0.001), ('politik ', 0.001), ('zb ', 0.001), ('gerade', 0.001)] \n",
      "\n",
      "### Topic: 2 | weights_mean: 0.0011\n",
      "[('video ', 0.002), ('deutschland ', 0.001), ('menschen ', 0.001), ('cdu ', 0.001), ('klar ', 0.001), ('grünen ', 0.001), ('gemacht ', 0.001), ('politik ', 0.001), ('gut ', 0.001), ('recht', 0.001)] \n",
      "\n",
      "### Topic: 3 | weights_mean: 0.0012\n",
      "[('rezo ', 0.002), ('video ', 0.002), ('meinung ', 0.001), ('deutschland ', 0.001), ('lügen ', 0.001), ('cdu ', 0.001), ('bitte ', 0.001), ('fakten ', 0.001), ('lo ', 0.001), ('parteien', 0.001)] \n",
      "\n",
      "### Topic: 4 | weights_mean: 0.001\n",
      "[('gut ', 0.001), ('geld ', 0.001), ('grünen ', 0.001), ('land ', 0.001), ('video ', 0.001), ('meinung ', 0.001), ('kommen ', 0.001), ('daran ', 0.001), ('leute ', 0.001), ('rezo', 0.001)] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## 2019-11 | 4 Topics | coherence 0.795320930933233\n",
      "\n",
      "### Topic: 1 | weights_mean: 0.0012\n",
      "[('menschen ', 0.002), ('cdu ', 0.002), ('partei ', 0.001), ('afd ', 0.001), ('leute ', 0.001), ('gut ', 0.001), ('meinung ', 0.001), ('deutschland ', 0.001), ('erde ', 0.001), ('schön', 0.001)] \n",
      "\n",
      "### Topic: 2 | weights_mean: 0.0015\n",
      "[('video ', 0.002), ('land ', 0.002), ('partei ', 0.002), ('grünen ', 0.002), ('cdu ', 0.002), ('afd ', 0.001), ('parteien ', 0.001), ('meinung ', 0.001), ('gut ', 0.001), ('menschen', 0.001)] \n",
      "\n",
      "### Topic: 3 | weights_mean: 0.001\n",
      "[('video ', 0.001), ('grünen ', 0.001), ('eher ', 0.001), ('schlecht ', 0.001), ('arbeit ', 0.001), ('wissen ', 0.001), ('glauben ', 0.001), ('cdu ', 0.001), ('passieren ', 0.001), ('rezo', 0.001)] \n",
      "\n",
      "### Topic: 4 | weights_mean: 0.0014\n",
      "[('cdu ', 0.002), ('grünen ', 0.002), ('wählen ', 0.002), ('deutschland ', 0.002), ('afd ', 0.001), ('gut ', 0.001), ('vielleicht ', 0.001), ('parteien ', 0.001), ('video ', 0.001), ('rezo', 0.001)] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## 2019-12 | 8 Topics | coherence 0.8040753880855329\n",
      "\n",
      "### Topic: 1 | weights_mean: 0.0012\n",
      "[('rezo ', 0.003), ('afd ', 0.001), ('video ', 0.001), ('wählen ', 0.001), ('besser ', 0.001), ('cdu ', 0.001), ('meinung ', 0.001), ('niemand ', 0.001), ('daran ', 0.001), ('deutschland', 0.001)] \n",
      "\n",
      "### Topic: 2 | weights_mean: 0.0012\n",
      "[('klar ', 0.002), ('afd ', 0.002), ('deutschland ', 0.001), ('vielleicht ', 0.001), ('frage ', 0.001), ('partei ', 0.001), ('antworten ', 0.001), ('einzige ', 0.001), ('okay ', 0.001), ('finde', 0.001)] \n",
      "\n",
      "### Topic: 3 | weights_mean: 0.0013\n",
      "[('video ', 0.002), ('wirklich ', 0.002), ('deutschland ', 0.002), ('afd ', 0.001), ('recht ', 0.001), ('grünen ', 0.001), ('echt ', 0.001), ('jemand ', 0.001), ('geschrieben ', 0.001), ('menschen', 0.001)] \n",
      "\n",
      "### Topic: 4 | weights_mean: 0.0014\n",
      "[('afd ', 0.002), ('grünen ', 0.002), ('politik ', 0.002), ('cdu ', 0.002), ('rezo ', 0.001), ('meinung ', 0.001), ('partei ', 0.001), ('deutschland ', 0.001), ('video ', 0.001), ('parteien', 0.001)] \n",
      "\n",
      "### Topic: 5 | weights_mean: 0.0011\n",
      "[('menschen ', 0.002), ('afd ', 0.001), ('partei ', 0.001), ('trotzdem ', 0.001), ('etc ', 0.001), ('finde ', 0.001), ('lieber ', 0.001), ('kommentar ', 0.001), ('rezo ', 0.001), ('zeit', 0.001)] \n",
      "\n",
      "### Topic: 6 | weights_mean: 0.0011\n",
      "[('video ', 0.002), ('besser ', 0.001), ('leben ', 0.001), ('cdu ', 0.001), ('eigene ', 0.001), ('menschen ', 0.001), ('schaut ', 0.001), ('millionen ', 0.001), ('lass ', 0.001), ('ganze', 0.001)] \n",
      "\n",
      "### Topic: 7 | weights_mean: 0.0011\n",
      "[('welt ', 0.002), ('schau ', 0.001), ('grünen ', 0.001), ('bitte ', 0.001), ('menschen ', 0.001), ('jahren ', 0.001), ('cdu ', 0.001), ('selber ', 0.001), ('video ', 0.001), ('dabei', 0.001)] \n",
      "\n",
      "### Topic: 8 | weights_mean: 0.0013\n",
      "[('video ', 0.002), ('menschen ', 0.002), ('grünen ', 0.002), ('ahnung ', 0.001), ('cdu ', 0.001), ('klima ', 0.001), ('rezo ', 0.001), ('afd ', 0.001), ('fakten ', 0.001), ('thema', 0.001)] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## 2020-01 | 4 Topics | coherence 0.8016539059701929\n",
      "\n",
      "### Topic: 1 | weights_mean: 0.0011\n",
      "[('cdu ', 0.002), ('parteien ', 0.001), ('afd ', 0.001), ('partei ', 0.001), ('video ', 0.001), ('leute ', 0.001), ('menschen ', 0.001), ('deutschland ', 0.001), ('hätte ', 0.001), ('spd', 0.001)] \n",
      "\n",
      "### Topic: 2 | weights_mean: 0.0011\n",
      "[('grünen ', 0.002), ('cdu ', 0.001), ('wirklich ', 0.001), ('gut ', 0.001), ('partei ', 0.001), ('video ', 0.001), ('gemacht ', 0.001), ('jahren ', 0.001), ('meinung ', 0.001), ('echt', 0.001)] \n",
      "\n",
      "### Topic: 3 | weights_mean: 0.0011\n",
      "[('grünen ', 0.002), ('video ', 0.001), ('lo ', 0.001), ('menschen ', 0.001), ('meinung ', 0.001), ('deutschland ', 0.001), ('leider ', 0.001), ('cdu ', 0.001), ('lügen ', 0.001), ('bitte', 0.001)] \n",
      "\n",
      "### Topic: 4 | weights_mean: 0.0012\n",
      "[('video ', 0.002), ('rezo ', 0.002), ('menschen ', 0.001), ('meinung ', 0.001), ('quellen ', 0.001), ('paar ', 0.001), ('grünen ', 0.001), ('afd ', 0.001), ('cdu ', 0.001), ('oh', 0.001)] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## 2020-02 | 4 Topics | coherence 0.8233715951489471\n",
      "\n",
      "### Topic: 1 | weights_mean: 0.0015\n",
      "[('partei ', 0.002), ('deutschland ', 0.002), ('grünen ', 0.002), ('gut ', 0.002), ('afd ', 0.002), ('cdu ', 0.001), ('leute ', 0.001), ('jahren ', 0.001), ('meinung ', 0.001), ('schau', 0.001)] \n",
      "\n",
      "### Topic: 2 | weights_mean: 0.001\n",
      "[('afd ', 0.001), ('klimawandel ', 0.001), ('richtig ', 0.001), ('menschen ', 0.001), ('video ', 0.001), ('angst ', 0.001), ('mensch ', 0.001), ('cdu ', 0.001), ('halt ', 0.001), ('glauben', 0.001)] \n",
      "\n",
      "### Topic: 3 | weights_mean: 0.0012\n",
      "[('partei ', 0.002), ('grünen ', 0.002), ('zitat ', 0.001), ('parteien ', 0.001), ('wählen ', 0.001), ('video ', 0.001), ('menschen ', 0.001), ('afd ', 0.001), ('deutschland ', 0.001), ('politik', 0.001)] \n",
      "\n",
      "### Topic: 4 | weights_mean: 0.0013\n",
      "[('video ', 0.002), ('cdu ', 0.002), ('grünen ', 0.002), ('rezo ', 0.001), ('politik ', 0.001), ('heute ', 0.001), ('klimawandel ', 0.001), ('afd ', 0.001), ('leute ', 0.001), ('lo', 0.001)] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## 2020-03 | 6 Topics | coherence 0.7837209909691777\n",
      "\n",
      "### Topic: 1 | weights_mean: 0.0013\n",
      "[('video ', 0.002), ('deutschland ', 0.002), ('partei ', 0.002), ('menschen ', 0.001), ('wählen ', 0.001), ('grünen ', 0.001), ('leider ', 0.001), ('afd ', 0.001), ('leute ', 0.001), ('warum', 0.001)] \n",
      "\n",
      "### Topic: 2 | weights_mean: 0.0011\n",
      "[('cdu ', 0.002), ('video ', 0.001), ('gut ', 0.001), ('klar ', 0.001), ('deutschland ', 0.001), ('wirklich ', 0.001), ('hätte ', 0.001), ('gerade ', 0.001), ('menschen ', 0.001), ('warum', 0.001)] \n",
      "\n",
      "### Topic: 3 | weights_mean: 0.001\n",
      "[('leben ', 0.001), ('leute ', 0.001), ('politik ', 0.001), ('wärmsten ', 0.001), ('arbeitsplätze ', 0.001), ('afd ', 0.001), ('cdu ', 0.001), ('video ', 0.001), ('meinung ', 0.001), ('rezo', 0.001)] \n",
      "\n",
      "### Topic: 4 | weights_mean: 0.0011\n",
      "[('video ', 0.002), ('liebe ', 0.001), ('rezo ', 0.001), ('bitte ', 0.001), ('recht ', 0.001), ('meinung ', 0.001), ('nein ', 0.001), ('kosten ', 0.001), ('kontrolliert ', 0.001), ('ekelhaften', 0.001)] \n",
      "\n",
      "### Topic: 5 | weights_mean: 0.0013\n",
      "[('grünen ', 0.002), ('afd ', 0.002), ('klimawandel ', 0.002), ('cdu ', 0.001), ('deutschland ', 0.001), ('welt ', 0.001), ('meinung ', 0.001), ('leben ', 0.001), ('politik ', 0.001), ('menschen', 0.001)] \n",
      "\n",
      "### Topic: 6 | weights_mean: 0.0012\n",
      "[('afd ', 0.002), ('grünen ', 0.002), ('rezo ', 0.001), ('klima ', 0.001), ('leben ', 0.001), ('partei ', 0.001), ('klimawandel ', 0.001), ('gut ', 0.001), ('menschen ', 0.001), ('erde', 0.001)] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## 2020-04 | 4 Topics | coherence 0.8006558791067662\n",
      "\n",
      "### Topic: 1 | weights_mean: 0.0012\n",
      "[('grünen ', 0.002), ('video ', 0.002), ('afd ', 0.001), ('wählen ', 0.001), ('deutschland ', 0.001), ('leute ', 0.001), ('menschen ', 0.001), ('meinung ', 0.001), ('klimawandel ', 0.001), ('gut', 0.001)] \n",
      "\n",
      "### Topic: 2 | weights_mean: 0.001\n",
      "[('video ', 0.001), ('menschen ', 0.001), ('cdu ', 0.001), ('lügen ', 0.001), ('kannst ', 0.001), ('afd ', 0.001), ('deutschland ', 0.001), ('lo ', 0.001), ('rezo ', 0.001), ('meinung', 0.001)] \n",
      "\n",
      "### Topic: 3 | weights_mean: 0.0011\n",
      "[('cdu ', 0.002), ('video ', 0.001), ('partei ', 0.001), ('afd ', 0.001), ('rezo ', 0.001), ('meinung ', 0.001), ('wirklich ', 0.001), ('grünen ', 0.001), ('gut ', 0.001), ('politik', 0.001)] \n",
      "\n",
      "### Topic: 4 | weights_mean: 0.0011\n",
      "[('video ', 0.002), ('cdu ', 0.001), ('vielleicht ', 0.001), ('rezo ', 0.001), ('menschen ', 0.001), ('afd ', 0.001), ('grünen ', 0.001), ('kinder ', 0.001), ('gut ', 0.001), ('leider', 0.001)] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## 2020-05 | 10 Topics | coherence 0.7885925353560453\n",
      "\n",
      "### Topic: 1 | weights_mean: 0.0013\n",
      "[('cdu ', 0.002), ('partei ', 0.002), ('afd ', 0.002), ('deutschland ', 0.001), ('video ', 0.001), ('sogar ', 0.001), ('möglich ', 0.001), ('menschen ', 0.001), ('frage ', 0.001), ('dinge', 0.001)] \n",
      "\n",
      "### Topic: 2 | weights_mean: 0.0019\n",
      "[('deutschland ', 0.002), ('rezo ', 0.002), ('spd ', 0.002), ('cdu ', 0.002), ('politik ', 0.002), ('grünen ', 0.002), ('video ', 0.002), ('parteien ', 0.002), ('menschen ', 0.002), ('dumm', 0.001)] \n",
      "\n",
      "### Topic: 3 | weights_mean: 0.001\n",
      "[('realität ', 0.001), ('menschen ', 0.001), ('partei ', 0.001), ('video ', 0.001), ('gehen ', 0.001), ('pflanzen ', 0.001), ('industrialisierung ', 0.001), ('leben ', 0.001), ('rezo ', 0.001), ('politik', 0.001)] \n",
      "\n",
      "### Topic: 4 | weights_mean: 0.002\n",
      "[('meinung ', 0.002), ('ekelhaften ', 0.002), ('absolut ', 0.002), ('beleidigen ', 0.002), ('hindern ', 0.002), ('locatwiesel ', 0.002), ('lasst ', 0.002), ('frei ', 0.002), ('fanboysgirls ', 0.002), ('andersdenkenden', 0.002)] \n",
      "\n",
      "### Topic: 5 | weights_mean: 0.0013\n",
      "[('rezo ', 0.003), ('video ', 0.002), ('afd ', 0.001), ('politik ', 0.001), ('echt ', 0.001), ('partei ', 0.001), ('klimawandel ', 0.001), ('grünen ', 0.001), ('cdu ', 0.001), ('wählen', 0.001)] \n",
      "\n",
      "### Topic: 6 | weights_mean: 0.001\n",
      "[('menschen ', 0.001), ('wirklich ', 0.001), ('leben ', 0.001), ('politik ', 0.001), ('quellen ', 0.001), ('welt ', 0.001), ('afd ', 0.001), ('wahlen ', 0.001), ('gründung ', 0.001), ('besser', 0.001)] \n",
      "\n",
      "### Topic: 7 | weights_mean: 0.0014\n",
      "[('dabei ', 0.002), ('wirklich ', 0.002), ('deutschland ', 0.002), ('partei ', 0.002), ('lo ', 0.001), ('video ', 0.001), ('klar ', 0.001), ('gehen ', 0.001), ('unterstützt ', 0.001), ('rezo', 0.001)] \n",
      "\n",
      "### Topic: 8 | weights_mean: 0.0013\n",
      "[('video ', 0.002), ('zitat ', 0.002), ('lüge ', 0.002), ('rezo ', 0.001), ('cdu ', 0.001), ('gemacht ', 0.001), ('generation ', 0.001), ('sowieso ', 0.001), ('gut ', 0.001), ('youtube', 0.001)] \n",
      "\n",
      "### Topic: 9 | weights_mean: 0.0018\n",
      "[('grünen ', 0.002), ('meinung ', 0.002), ('rezo ', 0.002), ('baerbock ', 0.002), ('annalena ', 0.002), ('parteien ', 0.002), ('video ', 0.002), ('afd ', 0.002), ('platz ', 0.001), ('deutschland', 0.001)] \n",
      "\n",
      "### Topic: 10 | weights_mean: 0.001\n",
      "[('partei ', 0.001), ('wissenschaftler ', 0.001), ('realität ', 0.001), ('eher ', 0.001), ('komplett ', 0.001), ('danke ', 0.001), ('problem ', 0.001), ('ab ', 0.001), ('besser ', 0.001), ('sekte', 0.001)] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## 2020-06 | 4 Topics | coherence 0.8064575583529004\n",
      "\n",
      "### Topic: 1 | weights_mean: 0.0012\n",
      "[('video ', 0.002), ('afd ', 0.002), ('partei ', 0.001), ('deutschland ', 0.001), ('cdu ', 0.001), ('menschen ', 0.001), ('leider ', 0.001), ('lügen ', 0.001), ('wählen ', 0.001), ('grünen', 0.001)] \n",
      "\n",
      "### Topic: 2 | weights_mean: 0.0012\n",
      "[('rezo ', 0.002), ('video ', 0.002), ('warum ', 0.001), ('cdu ', 0.001), ('afd ', 0.001), ('vielleicht ', 0.001), ('geld ', 0.001), ('problem ', 0.001), ('grünen ', 0.001), ('richtig', 0.001)] \n",
      "\n",
      "### Topic: 3 | weights_mean: 0.0012\n",
      "[('menschen ', 0.002), ('grünen ', 0.002), ('video ', 0.001), ('meinung ', 0.001), ('deutschland ', 0.001), ('afd ', 0.001), ('jahren ', 0.001), ('warum ', 0.001), ('wählen ', 0.001), ('partei', 0.001)] \n",
      "\n",
      "### Topic: 4 | weights_mean: 0.0012\n",
      "[('video ', 0.002), ('cdu ', 0.002), ('meinung ', 0.001), ('rezo ', 0.001), ('wählen ', 0.001), ('menschen ', 0.001), ('partei ', 0.001), ('klar ', 0.001), ('deutschland ', 0.001), ('grünen', 0.001)] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## 2020-07 | 14 Topics | coherence 0.784859127773749\n",
      "\n",
      "### Topic: 1 | weights_mean: 0.0013\n",
      "[('video ', 0.002), ('deutschland ', 0.002), ('cdu ', 0.002), ('widerlegt ', 0.001), ('gerne ', 0.001), ('naja ', 0.001), ('stehen ', 0.001), ('art ', 0.001), ('afd ', 0.001), ('parteien', 0.001)] \n",
      "\n",
      "### Topic: 2 | weights_mean: 0.0014\n",
      "[('menschen ', 0.002), ('grünen ', 0.002), ('quellen ', 0.002), ('video ', 0.002), ('cdu ', 0.001), ('politik ', 0.001), ('deutschland ', 0.001), ('land ', 0.001), ('gut ', 0.001), ('klar', 0.001)] \n",
      "\n",
      "### Topic: 3 | weights_mean: 0.0015\n",
      "[('partei ', 0.002), ('ändern ', 0.002), ('lo ', 0.002), ('zukunft ', 0.002), ('system ', 0.002), ('eigene ', 0.001), ('nehmen ', 0.001), ('russland ', 0.001), ('stefan ', 0.001), ('cdu', 0.001)] \n",
      "\n",
      "### Topic: 4 | weights_mean: 0.0014\n",
      "[('menschen ', 0.002), ('warum ', 0.002), ('jemand ', 0.002), ('zukunft ', 0.002), ('video ', 0.001), ('los ', 0.001), ('rechtsradikal ', 0.001), ('denken ', 0.001), ('fakten ', 0.001), ('punkt', 0.001)] \n",
      "\n",
      "### Topic: 5 | weights_mean: 0.0017\n",
      "[('grünen ', 0.002), ('auto ', 0.002), ('meinung ', 0.002), ('wählt ', 0.002), ('deutschland ', 0.002), ('cdu ', 0.002), ('seite ', 0.002), ('klar ', 0.001), ('propaganda ', 0.001), ('hinweis', 0.001)] \n",
      "\n",
      "### Topic: 6 | weights_mean: 0.0014\n",
      "[('grünen ', 0.003), ('angst ', 0.002), ('wählen ', 0.002), ('video ', 0.001), ('demokratie ', 0.001), ('weiterhin ', 0.001), ('partei ', 0.001), ('rezo ', 0.001), ('räumt ', 0.001), ('spitzenkandidat', 0.001)] \n",
      "\n",
      "### Topic: 7 | weights_mean: 0.0021\n",
      "[('lo ', 0.003), ('afd ', 0.002), ('lügen ', 0.002), ('grünen ', 0.002), ('fake ', 0.002), ('richtig ', 0.002), ('empfänger ', 0.002), ('account ', 0.002), ('einsam ', 0.002), ('dahinvegetiert', 0.002)] \n",
      "\n",
      "### Topic: 8 | weights_mean: 0.0017\n",
      "[('cdu ', 0.002), ('rezo ', 0.002), ('video ', 0.002), ('partei ', 0.002), ('politik ', 0.002), ('welt ', 0.002), ('afd ', 0.002), ('endlich ', 0.001), ('wählen ', 0.001), ('richtig', 0.001)] \n",
      "\n",
      "### Topic: 9 | weights_mean: 0.0016\n",
      "[('cdu ', 0.002), ('stimme ', 0.002), ('video ', 0.002), ('partei ', 0.002), ('bitte ', 0.002), ('grünen ', 0.002), ('gute ', 0.001), ('menschen ', 0.001), ('annalena ', 0.001), ('baerbock', 0.001)] \n",
      "\n",
      "### Topic: 10 | weights_mean: 0.0013\n",
      "[('wählt ', 0.002), ('menschen ', 0.002), ('kannst ', 0.002), ('wortschöpfung ', 0.001), ('reaktion ', 0.001), ('spd ', 0.001), ('leben ', 0.001), ('video ', 0.001), ('nein ', 0.001), ('erde', 0.001)] \n",
      "\n",
      "### Topic: 11 | weights_mean: 0.0014\n",
      "[('fakten ', 0.002), ('cdu ', 0.002), ('partei ', 0.002), ('afd ', 0.002), ('punkten ', 0.001), ('plagen ', 0.001), ('genug ', 0.001), ('leute ', 0.001), ('rezo ', 0.001), ('sollten', 0.001)] \n",
      "\n",
      "### Topic: 12 | weights_mean: 0.0015\n",
      "[('reden ', 0.002), ('menschen ', 0.002), ('cdu ', 0.002), ('politik ', 0.002), ('parteien ', 0.002), ('grünen ', 0.001), ('getan ', 0.001), ('leute ', 0.001), ('video ', 0.001), ('meinung', 0.001)] \n",
      "\n",
      "### Topic: 13 | weights_mean: 0.0021\n",
      "[('cdu ', 0.003), ('parteien ', 0.003), ('video ', 0.002), ('afd ', 0.002), ('partei ', 0.002), ('überhaupt ', 0.002), ('spd ', 0.002), ('eu ', 0.002), ('geld ', 0.002), ('leute', 0.001)] \n",
      "\n",
      "### Topic: 14 | weights_mean: 0.0021\n",
      "[('gut ', 0.003), ('rezo ', 0.002), ('grünen ', 0.002), ('deutschland ', 0.002), ('denke ', 0.002), ('meinung ', 0.002), ('politik ', 0.002), ('geld ', 0.002), ('leider ', 0.002), ('menschen', 0.002)] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## 2020-08 | 4 Topics | coherence 0.8112649674960417\n",
      "\n",
      "### Topic: 1 | weights_mean: 0.001\n",
      "[('video ', 0.001), ('menschen ', 0.001), ('deutschland ', 0.001), ('leute ', 0.001), ('user ', 0.001), ('lo ', 0.001), ('fake ', 0.001), ('welt ', 0.001), ('mehreren ', 0.001), ('cdu', 0.001)] \n",
      "\n",
      "### Topic: 2 | weights_mean: 0.0011\n",
      "[('video ', 0.002), ('deutschland ', 0.001), ('cdu ', 0.001), ('afd ', 0.001), ('gut ', 0.001), ('klima ', 0.001), ('klimawandel ', 0.001), ('menschen ', 0.001), ('grünen ', 0.001), ('rezo', 0.001)] \n",
      "\n",
      "### Topic: 3 | weights_mean: 0.0011\n",
      "[('grünen ', 0.002), ('wählen ', 0.001), ('afd ', 0.001), ('cdu ', 0.001), ('video ', 0.001), ('erst ', 0.001), ('parteien ', 0.001), ('fakten ', 0.001), ('menschen ', 0.001), ('rezo', 0.001)] \n",
      "\n",
      "### Topic: 4 | weights_mean: 0.0013\n",
      "[('video ', 0.002), ('partei ', 0.002), ('rezo ', 0.002), ('bitte ', 0.001), ('parteien ', 0.001), ('meinung ', 0.001), ('afd ', 0.001), ('cdu ', 0.001), ('gut ', 0.001), ('grünen', 0.001)] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## 2020-09 | 4 Topics | coherence 0.8056557414738404\n",
      "\n",
      "### Topic: 1 | weights_mean: 0.001\n",
      "[('rezo ', 0.001), ('afd ', 0.001), ('menschen ', 0.001), ('video ', 0.001), ('gut ', 0.001), ('cdu ', 0.001), ('klimawandel ', 0.001), ('leider ', 0.001), ('wählen ', 0.001), ('grünen', 0.001)] \n",
      "\n",
      "### Topic: 2 | weights_mean: 0.0013\n",
      "[('afd ', 0.002), ('grünen ', 0.002), ('video ', 0.002), ('cdu ', 0.001), ('wählen ', 0.001), ('deutschland ', 0.001), ('menschen ', 0.001), ('partei ', 0.001), ('meinung ', 0.001), ('jemand', 0.001)] \n",
      "\n",
      "### Topic: 3 | weights_mean: 0.0011\n",
      "[('afd ', 0.002), ('grünen ', 0.001), ('video ', 0.001), ('meinung ', 0.001), ('politik ', 0.001), ('jahren ', 0.001), ('rezo ', 0.001), ('parteien ', 0.001), ('kinder ', 0.001), ('warum', 0.001)] \n",
      "\n",
      "### Topic: 4 | weights_mean: 0.001\n",
      "[('video ', 0.001), ('cdu ', 0.001), ('wählen ', 0.001), ('afd ', 0.001), ('partei ', 0.001), ('menschen ', 0.001), ('kannst ', 0.001), ('parteien ', 0.001), ('klar ', 0.001), ('klimawandel', 0.001)] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## 2020-10 | 14 Topics | coherence 0.7770155666565027\n",
      "\n",
      "### Topic: 1 | weights_mean: 0.0015\n",
      "[('video ', 0.003), ('welt ', 0.002), ('rezo ', 0.002), ('leben ', 0.002), ('wissenschaft ', 0.001), ('vielleicht ', 0.001), ('grüne ', 0.001), ('wissenschaftler ', 0.001), ('quellen ', 0.001), ('erde', 0.001)] \n",
      "\n",
      "### Topic: 2 | weights_mean: 0.0011\n",
      "[('gut ', 0.002), ('eben ', 0.001), ('grünen ', 0.001), ('afd ', 0.001), ('sieht ', 0.001), ('sachen ', 0.001), ('jemand ', 0.001), ('cdu ', 0.001), ('halt ', 0.001), ('jahren', 0.001)] \n",
      "\n",
      "### Topic: 3 | weights_mean: 0.0027\n",
      "[('grünen ', 0.004), ('afd ', 0.004), ('video ', 0.003), ('meinung ', 0.003), ('cdu ', 0.003), ('partei ', 0.002), ('warum ', 0.002), ('frage ', 0.002), ('menschen ', 0.002), ('rezo', 0.002)] \n",
      "\n",
      "### Topic: 4 | weights_mean: 0.0012\n",
      "[('gut ', 0.002), ('usa ', 0.002), ('video ', 0.001), ('demokratie ', 0.001), ('dagegen ', 0.001), ('cdu ', 0.001), ('unternehmen ', 0.001), ('erst ', 0.001), ('vielleicht ', 0.001), ('gemacht', 0.001)] \n",
      "\n",
      "### Topic: 5 | weights_mean: 0.0011\n",
      "[('parteien ', 0.002), ('menschen ', 0.001), ('leider ', 0.001), ('leistung ', 0.001), ('umwelt ', 0.001), ('weigerst ', 0.001), ('wählen ', 0.001), ('vielen ', 0.001), ('mensch ', 0.001), ('problem', 0.001)] \n",
      "\n",
      "### Topic: 6 | weights_mean: 0.0011\n",
      "[('menschen ', 0.002), ('afd ', 0.001), ('cdu ', 0.001), ('sache ', 0.001), ('bitte ', 0.001), ('jungen ', 0.001), ('rezo ', 0.001), ('argumente ', 0.001), ('vertrauen ', 0.001), ('video', 0.001)] \n",
      "\n",
      "### Topic: 7 | weights_mean: 0.0011\n",
      "[('menschen ', 0.002), ('interessiert ', 0.001), ('lieber ', 0.001), ('schönen ', 0.001), ('zb ', 0.001), ('video ', 0.001), ('wahrheit ', 0.001), ('eigene ', 0.001), ('leute ', 0.001), ('art', 0.001)] \n",
      "\n",
      "### Topic: 8 | weights_mean: 0.0012\n",
      "[('rezo ', 0.002), ('statt ', 0.002), ('richtig ', 0.001), ('sollten ', 0.001), ('usa ', 0.001), ('gleich ', 0.001), ('eigenen ', 0.001), ('wählen ', 0.001), ('meinung ', 0.001), ('parteien', 0.001)] \n",
      "\n",
      "### Topic: 9 | weights_mean: 0.0013\n",
      "[('afd ', 0.002), ('partei ', 0.002), ('zeit ', 0.002), ('worte ', 0.001), ('möglich ', 0.001), ('video ', 0.001), ('rezo ', 0.001), ('deutschland ', 0.001), ('ländern ', 0.001), ('iv', 0.001)] \n",
      "\n",
      "### Topic: 10 | weights_mean: 0.0019\n",
      "[('grünen ', 0.002), ('partei ', 0.002), ('afd ', 0.002), ('leute ', 0.002), ('weiterhin ', 0.002), ('faschisten ', 0.002), ('jahren ', 0.002), ('gut ', 0.002), ('rezo ', 0.002), ('menschen', 0.001)] \n",
      "\n",
      "### Topic: 11 | weights_mean: 0.001\n",
      "[('besser ', 0.001), ('gut ', 0.001), ('prof ', 0.001), ('gleiche ', 0.001), ('bildung ', 0.001), ('fisch ', 0.001), ('aussage ', 0.001), ('deutschland ', 0.001), ('master ', 0.001), ('gehe', 0.001)] \n",
      "\n",
      "### Topic: 12 | weights_mean: 0.002\n",
      "[('account ', 0.002), ('fake ', 0.002), ('mehreren ', 0.002), ('beleidigt ', 0.002), ('user ', 0.002), ('dahinvegetiert ', 0.002), ('empfänger ', 0.002), ('einsam ', 0.002), ('unterwegs ', 0.002), ('hartz', 0.002)] \n",
      "\n",
      "### Topic: 13 | weights_mean: 0.0014\n",
      "[('quellen ', 0.002), ('cdu ', 0.002), ('wissen ', 0.002), ('video ', 0.002), ('selber ', 0.001), ('rezo ', 0.001), ('grünen ', 0.001), ('spd ', 0.001), ('partei ', 0.001), ('lügen', 0.001)] \n",
      "\n",
      "### Topic: 14 | weights_mean: 0.0011\n",
      "[('video ', 0.002), ('prozent ', 0.001), ('rezo ', 0.001), ('wissen ', 0.001), ('fakten ', 0.001), ('extreme ', 0.001), ('deutschland ', 0.001), ('fast ', 0.001), ('menschen ', 0.001), ('hätte', 0.001)] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## 2020-11 | 6 Topics | coherence 0.7948259473277961\n",
      "\n",
      "### Topic: 1 | weights_mean: 0.001\n",
      "[('meinung ', 0.001), ('menschen ', 0.001), ('video ', 0.001), ('cdu ', 0.001), ('weniger ', 0.001), ('leute ', 0.001), ('darf ', 0.001), ('quellen ', 0.001), ('ändern ', 0.001), ('leider', 0.001)] \n",
      "\n",
      "### Topic: 2 | weights_mean: 0.001\n",
      "[('video ', 0.001), ('politik ', 0.001), ('jahren ', 0.001), ('afd ', 0.001), ('meinung ', 0.001), ('cdu ', 0.001), ('richtig ', 0.001), ('deutschland ', 0.001), ('quellen ', 0.001), ('wählen', 0.001)] \n",
      "\n",
      "### Topic: 3 | weights_mean: 0.0011\n",
      "[('video ', 0.002), ('gut ', 0.001), ('heute ', 0.001), ('lo ', 0.001), ('recht ', 0.001), ('meinung ', 0.001), ('davon ', 0.001), ('schön ', 0.001), ('wählen ', 0.001), ('irma', 0.001)] \n",
      "\n",
      "### Topic: 4 | weights_mean: 0.0016\n",
      "[('video ', 0.002), ('afd ', 0.002), ('partei ', 0.002), ('cdu ', 0.002), ('grünen ', 0.002), ('menschen ', 0.002), ('gut ', 0.001), ('rezo ', 0.001), ('parteien ', 0.001), ('deutschland', 0.001)] \n",
      "\n",
      "### Topic: 5 | weights_mean: 0.0012\n",
      "[('video ', 0.002), ('rezo ', 0.002), ('deutschland ', 0.001), ('meinung ', 0.001), ('menschen ', 0.001), ('parteien ', 0.001), ('leute ', 0.001), ('grünen ', 0.001), ('erst ', 0.001), ('problem', 0.001)] \n",
      "\n",
      "### Topic: 6 | weights_mean: 0.0011\n",
      "[('grünen ', 0.002), ('video ', 0.001), ('lo ', 0.001), ('cdu ', 0.001), ('wählen ', 0.001), ('menschen ', 0.001), ('bitte ', 0.001), ('user ', 0.001), ('faschisten ', 0.001), ('klar', 0.001)] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## 2020-12 | 4 Topics | coherence 0.812529080172667\n",
      "\n",
      "### Topic: 1 | weights_mean: 0.0011\n",
      "[('afd ', 0.002), ('partei ', 0.001), ('klar ', 0.001), ('land ', 0.001), ('sogar ', 0.001), ('rezo ', 0.001), ('welt ', 0.001), ('ne ', 0.001), ('grünen ', 0.001), ('themen', 0.001)] \n",
      "\n",
      "### Topic: 2 | weights_mean: 0.0012\n",
      "[('video ', 0.002), ('rezo ', 0.002), ('grünen ', 0.001), ('menschen ', 0.001), ('klimawandel ', 0.001), ('davon ', 0.001), ('leider ', 0.001), ('jahren ', 0.001), ('planeten ', 0.001), ('quellen', 0.001)] \n",
      "\n",
      "### Topic: 3 | weights_mean: 0.0014\n",
      "[('afd ', 0.002), ('grünen ', 0.002), ('partei ', 0.002), ('wählen ', 0.002), ('cdu ', 0.001), ('deutschland ', 0.001), ('video ', 0.001), ('menschen ', 0.001), ('parteien ', 0.001), ('gut', 0.001)] \n",
      "\n",
      "### Topic: 4 | weights_mean: 0.0011\n",
      "[('cdu ', 0.002), ('afd ', 0.001), ('video ', 0.001), ('meinung ', 0.001), ('deutschland ', 0.001), ('parteien ', 0.001), ('leider ', 0.001), ('politik ', 0.001), ('menschen ', 0.001), ('user', 0.001)] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## 2021-01 | 4 Topics | coherence 0.8036756093680203\n",
      "\n",
      "### Topic: 1 | weights_mean: 0.001\n",
      "[('partei ', 0.001), ('afd ', 0.001), ('grünen ', 0.001), ('cdu ', 0.001), ('video ', 0.001), ('parteien ', 0.001), ('warum ', 0.001), ('meinung ', 0.001), ('leider ', 0.001), ('menschen', 0.001)] \n",
      "\n",
      "### Topic: 2 | weights_mean: 0.001\n",
      "[('grünen ', 0.001), ('afd ', 0.001), ('rezo ', 0.001), ('wirklich ', 0.001), ('deutschland ', 0.001), ('menschen ', 0.001), ('video ', 0.001), ('gut ', 0.001), ('zeit ', 0.001), ('cdu', 0.001)] \n",
      "\n",
      "### Topic: 3 | weights_mean: 0.0012\n",
      "[('cdu ', 0.002), ('video ', 0.002), ('rezo ', 0.001), ('afd ', 0.001), ('menschen ', 0.001), ('meinung ', 0.001), ('politik ', 0.001), ('leute ', 0.001), ('partei ', 0.001), ('deutschland', 0.001)] \n",
      "\n",
      "### Topic: 4 | weights_mean: 0.0013\n",
      "[('video ', 0.002), ('cdu ', 0.002), ('afd ', 0.002), ('rezo ', 0.001), ('deutschland ', 0.001), ('gut ', 0.001), ('wählen ', 0.001), ('menschen ', 0.001), ('lügen ', 0.001), ('partei', 0.001)] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## 2021-02 | 8 Topics | coherence 0.7770067446044354\n",
      "\n",
      "### Topic: 1 | weights_mean: 0.001\n",
      "[('eingeschaltet ', 0.001), ('umfrage ', 0.001), ('verein ', 0.001), ('oberflächlich ', 0.001), ('hingegen ', 0.001), ('mi ', 0.001), ('schaffst ', 0.001), ('zeichen ', 0.001), ('beeindruckend ', 0.001), ('entstand', 0.001)] \n",
      "\n",
      "### Topic: 2 | weights_mean: 0.0021\n",
      "[('baerbock ', 0.003), ('annalena ', 0.002), ('grünen ', 0.002), ('faschist ', 0.002), ('platz ', 0.002), ('achtung ', 0.002), ('bayern ', 0.002), ('weiterhin ', 0.002), ('offiziell ', 0.002), ('saarland', 0.002)] \n",
      "\n",
      "### Topic: 3 | weights_mean: 0.0035\n",
      "[('video ', 0.006), ('cdu ', 0.004), ('rezo ', 0.004), ('menschen ', 0.003), ('meinung ', 0.003), ('grünen ', 0.003), ('gut ', 0.003), ('quellen ', 0.003), ('wählen ', 0.003), ('klimawandel', 0.003)] \n",
      "\n",
      "### Topic: 4 | weights_mean: 0.001\n",
      "[('lehrer ', 0.001), ('scheinbar ', 0.001), ('senken ', 0.001), ('bezug ', 0.001), ('jugoslawien ', 0.001), ('inhalte ', 0.001), ('wolltest ', 0.001), ('zugelassen ', 0.001), ('magst ', 0.001), ('wahlkampf', 0.001)] \n",
      "\n",
      "### Topic: 5 | weights_mean: 0.0013\n",
      "[('beleidigt ', 0.002), ('gelaber ', 0.002), ('tubeone ', 0.002), ('schmitt ', 0.001), ('user ', 0.001), ('bekannte ', 0.001), ('meist ', 0.001), ('freue ', 0.001), ('udssr ', 0.001), ('einstein', 0.001)] \n",
      "\n",
      "### Topic: 6 | weights_mean: 0.0027\n",
      "[('afd ', 0.004), ('menschen ', 0.003), ('partei ', 0.003), ('grünen ', 0.003), ('deutschland ', 0.003), ('parteien ', 0.003), ('rezo ', 0.002), ('heute ', 0.002), ('politik ', 0.002), ('video', 0.002)] \n",
      "\n",
      "### Topic: 7 | weights_mean: 0.001\n",
      "[('hauptsächlich ', 0.001), ('hält ', 0.001), ('voll ', 0.001), ('afd ', 0.001), ('gegangen ', 0.001), ('bild ', 0.001), ('meinung ', 0.001), ('ergebnis ', 0.001), ('gehalt ', 0.001), ('eingestellt', 0.001)] \n",
      "\n",
      "### Topic: 8 | weights_mean: 0.001\n",
      "[('erwachsen ', 0.001), ('verbote ', 0.001), ('suv ', 0.001), ('nachher ', 0.001), ('perfekt ', 0.001), ('ecke ', 0.001), ('hauptsächlich ', 0.001), ('herbert ', 0.001), ('nimmst ', 0.001), ('faschismus', 0.001)] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## 2021-03 | 6 Topics | coherence 0.7821998843415966\n",
      "\n",
      "### Topic: 1 | weights_mean: 0.002\n",
      "[('annalena ', 0.002), ('baerbock ', 0.002), ('spitzenkandidat ', 0.002), ('antidemokratisch ', 0.002), ('saarland ', 0.002), ('räumt ', 0.002), ('antidemokratischen ', 0.002), ('männerfeindlich ', 0.002), ('männerfeindlichen ', 0.002), ('offiziell', 0.002)] \n",
      "\n",
      "### Topic: 2 | weights_mean: 0.001\n",
      "[('klimapanik ', 0.001), ('ausgewählte ', 0.001), ('herausziehen ', 0.001), ('wahlbeeinflussung ', 0.001), ('malediven ', 0.001), ('biste ', 0.001), ('toll ', 0.001), ('verbrechen ', 0.001), ('gollum ', 0.001), ('einseitigkeit', 0.001)] \n",
      "\n",
      "### Topic: 3 | weights_mean: 0.0015\n",
      "[('hindern ', 0.002), ('andersdenkenden ', 0.002), ('ekelhaften ', 0.002), ('verkommen ', 0.002), ('widerlich ', 0.002), ('lasst ', 0.001), ('user ', 0.001), ('frei ', 0.001), ('besonders ', 0.001), ('fanboysgirls', 0.001)] \n",
      "\n",
      "### Topic: 4 | weights_mean: 0.001\n",
      "[('männliche ', 0.001), ('straftaten ', 0.001), ('sowohl ', 0.001), ('temperatur ', 0.001), ('informiere ', 0.001), ('evolution ', 0.001), ('problematik ', 0.001), ('tierschutzpartei ', 0.001), ('wirtschaftlichsoziale ', 0.001), ('ankunft', 0.001)] \n",
      "\n",
      "### Topic: 5 | weights_mean: 0.001\n",
      "[('dahinvegetiert ', 0.001), ('einsam ', 0.001), ('empfänger ', 0.001), ('account ', 0.001), ('löschen ', 0.001), ('vollstem ', 0.001), ('datei ', 0.001), ('nimmst ', 0.001), ('herzen ', 0.001), ('unmengen', 0.001)] \n",
      "\n",
      "### Topic: 6 | weights_mean: 0.0029\n",
      "[('video ', 0.004), ('afd ', 0.003), ('cdu ', 0.003), ('rezo ', 0.003), ('grünen ', 0.003), ('deutschland ', 0.003), ('menschen ', 0.003), ('partei ', 0.003), ('meinung ', 0.002), ('gut', 0.002)] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## 2021-04 | 6 Topics | coherence 0.774933521464221\n",
      "\n",
      "### Topic: 1 | weights_mean: 0.0012\n",
      "[('annalena ', 0.002), ('baerbock ', 0.002), ('nwort ', 0.001), ('boomer ', 0.001), ('bla ', 0.001), ('forderte ', 0.001), ('eindringlich ', 0.001), ('hoffen ', 0.001), ('benutzte ', 0.001), ('boris', 0.001)] \n",
      "\n",
      "### Topic: 2 | weights_mean: 0.001\n",
      "[('ausgewählte ', 0.001), ('irak ', 0.001), ('malediven ', 0.001), ('pädophilie ', 0.001), ('einseitigkeit ', 0.001), ('datei ', 0.001), ('zurzeit ', 0.001), ('pdf ', 0.001), ('herzen ', 0.001), ('social', 0.001)] \n",
      "\n",
      "### Topic: 3 | weights_mean: 0.001\n",
      "[('enthalten ', 0.001), ('antidemokratischen ', 0.001), ('spitzenkandidat ', 0.001), ('männerfeindlichen ', 0.001), ('räumt ', 0.001), ('saarland ', 0.001), ('gewählte ', 0.001), ('antidemokratisch ', 0.001), ('ertragen ', 0.001), ('fordern', 0.001)] \n",
      "\n",
      "### Topic: 4 | weights_mean: 0.003\n",
      "[('video ', 0.004), ('cdu ', 0.003), ('afd ', 0.003), ('rezo ', 0.003), ('grünen ', 0.003), ('menschen ', 0.003), ('deutschland ', 0.003), ('partei ', 0.003), ('meinung ', 0.003), ('gut', 0.002)] \n",
      "\n",
      "### Topic: 5 | weights_mean: 0.002\n",
      "[('lügen ', 0.003), ('unterstellungen ', 0.002), ('lo ', 0.002), ('faschisten ', 0.002), ('achtung ', 0.002), ('beleidigungen ', 0.002), ('stefan ', 0.002), ('gespammt ', 0.002), ('cordes ', 0.002), ('axel', 0.001)] \n",
      "\n",
      "### Topic: 6 | weights_mean: 0.001\n",
      "[('zitat ', 0.001), ('zerbombt ', 0.001), ('waziri ', 0.001), ('miene ', 0.001), ('existenzberechtigung ', 0.001), ('wünschte ', 0.001), ('sebastian ', 0.001), ('einsam ', 0.001), ('volkstod ', 0.001), ('terror', 0.001)] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## 2021-05 | 4 Topics | coherence 0.8000039601760731\n",
      "\n",
      "### Topic: 1 | weights_mean: 0.002\n",
      "[('irma ', 0.002), ('user ', 0.002), ('andersdenkenden ', 0.002), ('widerlich ', 0.002), ('ekelhaften ', 0.002), ('locatwiesel ', 0.002), ('fanboysgirls ', 0.002), ('hindern ', 0.002), ('frei ', 0.002), ('beleidigen', 0.002)] \n",
      "\n",
      "### Topic: 2 | weights_mean: 0.0012\n",
      "[('annalena ', 0.002), ('baerbock ', 0.002), ('grünen ', 0.001), ('namentlich ', 0.001), ('gefördert ', 0.001), ('heuchler ', 0.001), ('weniger ', 0.001), ('nwort ', 0.001), ('handeln ', 0.001), ('gregor', 0.001)] \n",
      "\n",
      "### Topic: 3 | weights_mean: 0.0011\n",
      "[('vogel ', 0.002), ('streik ', 0.001), ('ork ', 0.001), ('entsprechen ', 0.001), ('bessere ', 0.001), ('aufhören ', 0.001), ('arm ', 0.001), ('xd ', 0.001), ('passt ', 0.001), ('helfen', 0.001)] \n",
      "\n",
      "### Topic: 4 | weights_mean: 0.0028\n",
      "[('afd ', 0.004), ('video ', 0.004), ('rezo ', 0.003), ('cdu ', 0.003), ('menschen ', 0.003), ('grünen ', 0.003), ('partei ', 0.002), ('deutschland ', 0.002), ('meinung ', 0.002), ('parteien', 0.002)] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## 2021-06 | 4 Topics | coherence 0.820006524537575\n",
      "\n",
      "### Topic: 1 | weights_mean: 0.0013\n",
      "[('video ', 0.002), ('cdu ', 0.002), ('rezo ', 0.002), ('deutschland ', 0.001), ('wirklich ', 0.001), ('bitte ', 0.001), ('afd ', 0.001), ('menschen ', 0.001), ('partei ', 0.001), ('recht', 0.001)] \n",
      "\n",
      "### Topic: 2 | weights_mean: 0.0012\n",
      "[('wählen ', 0.002), ('grünen ', 0.002), ('afd ', 0.001), ('partei ', 0.001), ('meinung ', 0.001), ('video ', 0.001), ('cdu ', 0.001), ('deutschland ', 0.001), ('parteien ', 0.001), ('jahren', 0.001)] \n",
      "\n",
      "### Topic: 3 | weights_mean: 0.0012\n",
      "[('video ', 0.002), ('deutschland ', 0.002), ('grünen ', 0.001), ('klar ', 0.001), ('menschen ', 0.001), ('meinung ', 0.001), ('leute ', 0.001), ('rezo ', 0.001), ('partei ', 0.001), ('warum', 0.001)] \n",
      "\n",
      "### Topic: 4 | weights_mean: 0.0012\n",
      "[('grünen ', 0.002), ('afd ', 0.002), ('baerbock ', 0.001), ('annalena ', 0.001), ('video ', 0.001), ('menschen ', 0.001), ('bitte ', 0.001), ('leider ', 0.001), ('rezo ', 0.001), ('cdu', 0.001)] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## 2021-07 | 4 Topics | coherence 0.7697345315812782\n",
      "\n",
      "### Topic: 1 | weights_mean: 0.0026\n",
      "[('video ', 0.003), ('afd ', 0.003), ('cdu ', 0.003), ('grünen ', 0.003), ('rezo ', 0.003), ('menschen ', 0.003), ('partei ', 0.002), ('deutschland ', 0.002), ('meinung ', 0.002), ('gut', 0.002)] \n",
      "\n",
      "### Topic: 2 | weights_mean: 0.0011\n",
      "[('baerbock ', 0.002), ('annalena ', 0.001), ('grünen ', 0.001), ('saarland ', 0.001), ('gewählte ', 0.001), ('männerfeindlichen ', 0.001), ('räumt ', 0.001), ('antidemokratischen ', 0.001), ('spitzenkandidat ', 0.001), ('männerfeindlich', 0.001)] \n",
      "\n",
      "### Topic: 3 | weights_mean: 0.001\n",
      "[('irma ', 0.001), ('faschisten ', 0.001), ('liebe ', 0.001), ('user ', 0.001), ('gespammt ', 0.001), ('widerlich ', 0.001), ('hindern ', 0.001), ('andersdenkenden ', 0.001), ('verkommen ', 0.001), ('ekelhaften', 0.001)] \n",
      "\n",
      "### Topic: 4 | weights_mean: 0.0002\n",
      "[('männliche ', 0.001), ('straftaten ', 0.001), ('kommentarfunktion ', 0.0), ('legion ', 0.0), ('zuspammen ', 0.0), ('faschistischen ', 0.0), ('muster ', 0.0), ('usern ', 0.0), ('diffamierungen ', 0.0), ('anna', 0.0)] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## 2021-08 | 6 Topics | coherence 0.794818149324653\n",
      "\n",
      "### Topic: 1 | weights_mean: 0.0013\n",
      "[('rezo ', 0.002), ('video ', 0.002), ('afd ', 0.002), ('quellen ', 0.001), ('warum ', 0.001), ('erst ', 0.001), ('cdu ', 0.001), ('wissenschaftler ', 0.001), ('menschen ', 0.001), ('grünen', 0.001)] \n",
      "\n",
      "### Topic: 2 | weights_mean: 0.0013\n",
      "[('grünen ', 0.003), ('leute ', 0.002), ('wählen ', 0.001), ('partei ', 0.001), ('cdu ', 0.001), ('video ', 0.001), ('rezo ', 0.001), ('menschen ', 0.001), ('meinung ', 0.001), ('afd', 0.001)] \n",
      "\n",
      "### Topic: 3 | weights_mean: 0.0012\n",
      "[('cdu ', 0.002), ('deutschland ', 0.002), ('video ', 0.001), ('partei ', 0.001), ('meinung ', 0.001), ('gut ', 0.001), ('klima ', 0.001), ('afd ', 0.001), ('rezo ', 0.001), ('welt', 0.001)] \n",
      "\n",
      "### Topic: 4 | weights_mean: 0.0011\n",
      "[('video ', 0.002), ('partei ', 0.001), ('gut ', 0.001), ('grünen ', 0.001), ('wissen ', 0.001), ('meinung ', 0.001), ('klar ', 0.001), ('genug ', 0.001), ('rezo ', 0.001), ('menschen', 0.001)] \n",
      "\n",
      "### Topic: 5 | weights_mean: 0.0012\n",
      "[('parteien ', 0.002), ('cdu ', 0.002), ('video ', 0.001), ('afd ', 0.001), ('rezo ', 0.001), ('deutschland ', 0.001), ('thema ', 0.001), ('partei ', 0.001), ('bundestag ', 0.001), ('prozent', 0.001)] \n",
      "\n",
      "### Topic: 6 | weights_mean: 0.0011\n",
      "[('video ', 0.002), ('parteien ', 0.001), ('ende ', 0.001), ('menschen ', 0.001), ('partei ', 0.001), ('klima ', 0.001), ('klimawandel ', 0.001), ('demokratie ', 0.001), ('cdu ', 0.001), ('grünen', 0.001)] \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 56;\n",
       "                var nbb_unformatted_code = \"nr_words = 10\\n\\n\\ndef get_topics_format(topics):\\n    topics_words = []\\n    for topic in topics:\\n        s = topic[1].split(\\\"+\\\")\\n        s = [tuple(x.split(\\\"*\\\")) for x in s]\\n        weights = [float(x[0]) for x in s]\\n        words = [x[1].replace('\\\"', \\\"\\\") for x in s]\\n        topics_words.append(list(zip(words, weights)))\\n    return topics_words\\n\\n\\n# for nr_t in num_topics_evaluated_lda:\\nfor idx, (key, value) in enumerate(corpus_d.items()):\\n    nr_t = num_topics_evaluated_lda[idx]\\n    lda_index = int((nr_t - 4) / 2)\\n    coherence_value = value[\\\"lda_models\\\"][lda_index][1]\\n    print(f\\\"## {key} | {nr_t} Topics | coherence {coherence_value}\\\\n\\\")\\n\\n    # TODO take model determined by \\\"num_topics_evaluated_lda\\\" list (best coherence), not first\\n    for i, topic_words in enumerate(\\n        get_topics_format(\\n            value[\\\"lda_models\\\"][lda_index][0].print_topics(num_words=nr_words)\\n        )\\n    ):\\n        weights_mean = round(sum([x[1] for x in topic_words]) / nr_words, 4)\\n        print(f\\\"### Topic: {i+1} | weights_mean: {weights_mean}\\\")\\n        print(topic_words, \\\"\\\\n\\\")\\n    print(\\\"\\\\n\\\\n\\\")\";\n",
       "                var nbb_formatted_code = \"nr_words = 10\\n\\n\\ndef get_topics_format(topics):\\n    topics_words = []\\n    for topic in topics:\\n        s = topic[1].split(\\\"+\\\")\\n        s = [tuple(x.split(\\\"*\\\")) for x in s]\\n        weights = [float(x[0]) for x in s]\\n        words = [x[1].replace('\\\"', \\\"\\\") for x in s]\\n        topics_words.append(list(zip(words, weights)))\\n    return topics_words\\n\\n\\n# for nr_t in num_topics_evaluated_lda:\\nfor idx, (key, value) in enumerate(corpus_d.items()):\\n    nr_t = num_topics_evaluated_lda[idx]\\n    lda_index = int((nr_t - 4) / 2)\\n    coherence_value = value[\\\"lda_models\\\"][lda_index][1]\\n    print(f\\\"## {key} | {nr_t} Topics | coherence {coherence_value}\\\\n\\\")\\n\\n    # TODO take model determined by \\\"num_topics_evaluated_lda\\\" list (best coherence), not first\\n    for i, topic_words in enumerate(\\n        get_topics_format(\\n            value[\\\"lda_models\\\"][lda_index][0].print_topics(num_words=nr_words)\\n        )\\n    ):\\n        weights_mean = round(sum([x[1] for x in topic_words]) / nr_words, 4)\\n        print(f\\\"### Topic: {i+1} | weights_mean: {weights_mean}\\\")\\n        print(topic_words, \\\"\\\\n\\\")\\n    print(\\\"\\\\n\\\\n\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nr_words = 10\n",
    "\n",
    "\n",
    "def get_topics_format(topics):\n",
    "    topics_words = []\n",
    "    for topic in topics:\n",
    "        s = topic[1].split(\"+\")\n",
    "        s = [tuple(x.split(\"*\")) for x in s]\n",
    "        weights = [float(x[0]) for x in s]\n",
    "        words = [x[1].replace('\"', \"\") for x in s]\n",
    "        topics_words.append(list(zip(words, weights)))\n",
    "    return topics_words\n",
    "\n",
    "\n",
    "# for nr_t in num_topics_evaluated_lda:\n",
    "for idx, (key, value) in enumerate(corpus_d.items()):\n",
    "    nr_t = num_topics_evaluated_lda[idx]\n",
    "    lda_index = int((nr_t - 4) / 2)\n",
    "    coherence_value = value[\"lda_models\"][lda_index][1]\n",
    "    print(f\"## {key} | {nr_t} Topics | coherence {coherence_value}\\n\")\n",
    "\n",
    "    # TODO take model determined by \"num_topics_evaluated_lda\" list (best coherence), not first\n",
    "    for i, topic_words in enumerate(\n",
    "        get_topics_format(\n",
    "            value[\"lda_models\"][lda_index][0].print_topics(num_words=nr_words)\n",
    "        )\n",
    "    ):\n",
    "        weights_mean = round(sum([x[1] for x in topic_words]) / nr_words, 4)\n",
    "        print(f\"### Topic: {i+1} | weights_mean: {weights_mean}\")\n",
    "        print(topic_words, \"\\n\")\n",
    "    print(\"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python38564bit13719079319b43f28007a75a272eccd3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
